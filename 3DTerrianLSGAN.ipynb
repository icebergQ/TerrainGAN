{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DCGAN Tutorial\n",
    "==============\n",
    "\n",
    "**Author**: `Nathan Inkawhich <https://github.com/inkawhich>`__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "------------\n",
    "\n",
    "This tutorial will give an introduction to DCGANs through an example. We\n",
    "will train a generative adversarial network (GAN) to generate new\n",
    "celebrities after showing it pictures of many real celebrities. Most of\n",
    "the code here is from the dcgan implementation in\n",
    "`pytorch/examples <https://github.com/pytorch/examples>`__, and this\n",
    "document will give a thorough explanation of the implementation and shed\n",
    "light on how and why this model works. But don’t worry, no prior\n",
    "knowledge of GANs is required, but it may require a first-timer to spend\n",
    "some time reasoning about what is actually happening under the hood.\n",
    "Also, for the sake of time it will help to have a GPU, or two. Lets\n",
    "start from the beginning.\n",
    "\n",
    "Generative Adversarial Networks\n",
    "-------------------------------\n",
    "\n",
    "What is a GAN?\n",
    "~~~~~~~~~~~~~~\n",
    "\n",
    "GANs are a framework for teaching a DL model to capture the training\n",
    "data’s distribution so we can generate new data from that same\n",
    "distribution. GANs were invented by Ian Goodfellow in 2014 and first\n",
    "described in the paper `Generative Adversarial\n",
    "Nets <https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf>`__.\n",
    "They are made of two distinct models, a *generator* and a\n",
    "*discriminator*. The job of the generator is to spawn ‘fake’ images that\n",
    "look like the training images. The job of the discriminator is to look\n",
    "at an image and output whether or not it is a real training image or a\n",
    "fake image from the generator. During training, the generator is\n",
    "constantly trying to outsmart the discriminator by generating better and\n",
    "better fakes, while the discriminator is working to become a better\n",
    "detective and correctly classify the real and fake images. The\n",
    "equilibrium of this game is when the generator is generating perfect\n",
    "fakes that look as if they came directly from the training data, and the\n",
    "discriminator is left to always guess at 50% confidence that the\n",
    "generator output is real or fake.\n",
    "\n",
    "Now, lets define some notation to be used throughout tutorial starting\n",
    "with the discriminator. Let $x$ be data representing an image.\n",
    "$D(x)$ is the discriminator network which outputs the (scalar)\n",
    "probability that $x$ came from training data rather than the\n",
    "generator. Here, since we are dealing with images the input to\n",
    "$D(x)$ is an image of CHW size 3x64x64. Intuitively, $D(x)$\n",
    "should be HIGH when $x$ comes from training data and LOW when\n",
    "$x$ comes from the generator. $D(x)$ can also be thought of\n",
    "as a traditional binary classifier.\n",
    "\n",
    "For the generator’s notation, let $z$ be a latent space vector\n",
    "sampled from a standard normal distribution. $G(z)$ represents the\n",
    "generator function which maps the latent vector $z$ to data-space.\n",
    "The goal of $G$ is to estimate the distribution that the training\n",
    "data comes from ($p_{data}$) so it can generate fake samples from\n",
    "that estimated distribution ($p_g$).\n",
    "\n",
    "So, $D(G(z))$ is the probability (scalar) that the output of the\n",
    "generator $G$ is a real image. As described in `Goodfellow’s\n",
    "paper <https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf>`__,\n",
    "$D$ and $G$ play a minimax game in which $D$ tries to\n",
    "maximize the probability it correctly classifies reals and fakes\n",
    "($logD(x)$), and $G$ tries to minimize the probability that\n",
    "$D$ will predict its outputs are fake ($log(1-D(G(x)))$).\n",
    "From the paper, the GAN loss function is\n",
    "\n",
    "\\begin{align}\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(z)))\\big]\\end{align}\n",
    "\n",
    "In theory, the solution to this minimax game is where\n",
    "$p_g = p_{data}$, and the discriminator guesses randomly if the\n",
    "inputs are real or fake. However, the convergence theory of GANs is\n",
    "still being actively researched and in reality models do not always\n",
    "train to this point.\n",
    "\n",
    "What is a DCGAN?\n",
    "~~~~~~~~~~~~~~~~\n",
    "\n",
    "A DCGAN is a direct extension of the GAN described above, except that it\n",
    "explicitly uses convolutional and convolutional-transpose layers in the\n",
    "discriminator and generator, respectively. It was first described by\n",
    "Radford et. al. in the paper `Unsupervised Representation Learning With\n",
    "Deep Convolutional Generative Adversarial\n",
    "Networks <https://arxiv.org/pdf/1511.06434.pdf>`__. The discriminator\n",
    "is made up of strided\n",
    "`convolution <https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d>`__\n",
    "layers, `batch\n",
    "norm <https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d>`__\n",
    "layers, and\n",
    "`LeakyReLU <https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU>`__\n",
    "activations. The input is a 3x64x64 input image and the output is a\n",
    "scalar probability that the input is from the real data distribution.\n",
    "The generator is comprised of\n",
    "`convolutional-transpose <https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d>`__\n",
    "layers, batch norm layers, and\n",
    "`ReLU <https://pytorch.org/docs/stable/nn.html#relu>`__ activations. The\n",
    "input is a latent vector, $z$, that is drawn from a standard\n",
    "normal distribution and the output is a 3x64x64 RGB image. The strided\n",
    "conv-transpose layers allow the latent vector to be transformed into a\n",
    "volume with the same shape as an image. In the paper, the authors also\n",
    "give some tips about how to setup the optimizers, how to calculate the\n",
    "loss functions, and how to initialize the model weights, all of which\n",
    "will be explained in the coming sections.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  6877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bdadd2f3f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "#manualSeed = 999\n",
    "manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs\n",
    "------\n",
    "\n",
    "Let’s define some inputs for the run:\n",
    "\n",
    "-  **dataroot** - the path to the root of the dataset folder. We will\n",
    "   talk more about the dataset in the next section\n",
    "-  **workers** - the number of worker threads for loading the data with\n",
    "   the DataLoader\n",
    "-  **batch_size** - the batch size used in training. The DCGAN paper\n",
    "   uses a batch size of 128\n",
    "-  **image_size** - the spatial size of the images used for training.\n",
    "   This implementation defaults to 64x64. If another size is desired,\n",
    "   the structures of D and G must be changed. See\n",
    "   `here <https://github.com/pytorch/examples/issues/70>`__ for more\n",
    "   details\n",
    "-  **nc** - number of color channels in the input images. For color\n",
    "   images this is 3\n",
    "-  **nz** - length of latent vector\n",
    "-  **ngf** - relates to the depth of feature maps carried through the\n",
    "   generator\n",
    "-  **ndf** - sets the depth of feature maps propagated through the\n",
    "   discriminator\n",
    "-  **num_epochs** - number of training epochs to run. Training for\n",
    "   longer will probably lead to better results but will also take much\n",
    "   longer\n",
    "-  **lr** - learning rate for training. As described in the DCGAN paper,\n",
    "   this number should be 0.0002\n",
    "-  **beta1** - beta1 hyperparameter for Adam optimizers. As described in\n",
    "   paper, this number should be 0.5\n",
    "-  **ngpu** - number of GPUs available. If this is 0, code will run in\n",
    "   CPU mode. If this number is greater than 0 it will run on that number\n",
    "   of GPUs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "#dataroot = \"C:/Users/yyhh/Desktop/Morpheus/data/celeba\"\n",
    "dataroot = \"data/HTile128\"\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 8\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 128\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 128\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 150\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "----\n",
    "\n",
    "In this tutorial we will use the `Celeb-A Faces\n",
    "dataset <http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html>`__ which can\n",
    "be downloaded at the linked site, or in `Google\n",
    "Drive <https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg>`__.\n",
    "The dataset will download as a file named *img_align_celeba.zip*. Once\n",
    "downloaded, create a directory named *celeba* and extract the zip file\n",
    "into that directory. Then, set the *dataroot* input for this notebook to\n",
    "the *celeba* directory you just created. The resulting directory\n",
    "structure should be:\n",
    "\n",
    "::\n",
    "\n",
    "   /path/to/celeba\n",
    "       -> img_align_celeba  \n",
    "           -> 188242.jpg\n",
    "           -> 173822.jpg\n",
    "           -> 284702.jpg\n",
    "           -> 537394.jpg\n",
    "              ...\n",
    "\n",
    "This is an important step because we will be using the ImageFolder\n",
    "dataset class, which requires there to be subdirectories in the\n",
    "dataset’s root folder. Now, we can create the dataset, create the\n",
    "dataloader, set the device to run on, and finally visualize some of the\n",
    "training data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# We can use an image folder dataset the way we have it setup.\n",
    "# Create the dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               #transforms.Grayscale(num_output_channels=1),\n",
    "                               transforms.ToTensor(),\n",
    "\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               #transforms.Normalize((0.5,), (0.5,)),\n",
    "\n",
    "                           ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)\n",
    "#print(len(dataloader))\n",
    "#print(dataloader)\n",
    "#nextitem= next(iter(dataloader))\n",
    "#print(type(dataloader))\n",
    "#print(type(next(iter(dataloader))))\n",
    "#print(len(next(iter(dataloader))))\n",
    "#print(nextitem)\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Plot some training images\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "print(type(real_batch))\n",
    "\n",
    "#plt.figure(figsize=(8,8))\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"Training Images\")\n",
    "#plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "real_batch = next(iter(dataloader))\n",
    "print(type(real_batch))\n",
    "print(type(real_batch[0]))\n",
    "print(len(real_batch[0][0][0]))\n",
    "#print(real_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2bdb3f29a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation\n",
    "--------------\n",
    "\n",
    "With our input parameters set and the dataset prepared, we can now get\n",
    "into the implementation. We will start with the weigth initialization\n",
    "strategy, then talk about the generator, discriminator, loss functions,\n",
    "and training loop in detail.\n",
    "\n",
    "Weight Initialization\n",
    "~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "From the DCGAN paper, the authors specify that all model weights shall\n",
    "be randomly initialized from a Normal distribution with mean=0,\n",
    "stdev=0.02. The ``weights_init`` function takes an initialized model as\n",
    "input and reinitializes all convolutional, convolutional-transpose, and\n",
    "batch normalization layers to meet this criteria. This function is\n",
    "applied to the models immediately after initialization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator\n",
    "~~~~~~~~~\n",
    "\n",
    "The generator, $G$, is designed to map the latent space vector\n",
    "($z$) to data-space. Since our data are images, converting\n",
    "$z$ to data-space means ultimately creating a RGB image with the\n",
    "same size as the training images (i.e. 3x64x64). In practice, this is\n",
    "accomplished through a series of strided two dimensional convolutional\n",
    "transpose layers, each paired with a 2d batch norm layer and a relu\n",
    "activation. The output of the generator is fed through a tanh function\n",
    "to return it to the input data range of $[-1,1]$. It is worth\n",
    "noting the existence of the batch norm functions after the\n",
    "conv-transpose layers, as this is a critical contribution of the DCGAN\n",
    "paper. These layers help with the flow of gradients during training. An\n",
    "image of the generator from the DCGAN paper is shown below.\n",
    "\n",
    ".. figure:: /_static/img/dcgan_generator.png\n",
    "   :alt: dcgan_generator\n",
    "\n",
    "Notice, the how the inputs we set in the input section (*nz*, *ngf*, and\n",
    "*nc*) influence the generator architecture in code. *nz* is the length\n",
    "of the z input vector, *ngf* relates to the size of the feature maps\n",
    "that are propagated through the generator, and *nc* is the number of\n",
    "channels in the output image (set to 3 for RGB images). Below is the\n",
    "code for the generator.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, npgu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.init_size = 128 // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(100, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can instantiate the generator and apply the ``weights_init``\n",
    "function. Check out the printed model to see how the generator object is\n",
    "structured.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (l1): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=131072, bias=True)\n",
      "  )\n",
      "  (conv_blocks): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (5): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n",
    "\n",
    "#from torchsummary import summary\n",
    "#summary(netG, input_size= (100, 1024, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator\n",
    "~~~~~~~~~~~~~\n",
    "\n",
    "As mentioned, the discriminator, $D$, is a binary classification\n",
    "network that takes an image as input and outputs a scalar probability\n",
    "that the input image is real (as opposed to fake). Here, $D$ takes\n",
    "a 3x64x64 input image, processes it through a series of Conv2d,\n",
    "BatchNorm2d, and LeakyReLU layers, and outputs the final probability\n",
    "through a Sigmoid activation function. This architecture can be extended\n",
    "with more layers if necessary for the problem, but there is significance\n",
    "to the use of the strided convolution, BatchNorm, and LeakyReLUs. The\n",
    "DCGAN paper mentions it is a good practice to use strided convolution\n",
    "rather than pooling to downsample because it lets the network learn its\n",
    "own pooling function. Also batch norm and leaky relu functions promote\n",
    "healthy gradient flow which is critical for the learning process of both\n",
    "$G$ and $D$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # The height and width of downsampled image\n",
    "        ds_size = 128 // 2 ** 4\n",
    "        self.adv_layer = nn.Linear(128 * ds_size ** 2, 1)\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as with the generator, we can create the discriminator, apply the\n",
    "``weights_init`` function, and print the model’s structure.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout2d(p=0.25, inplace=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Dropout2d(p=0.25, inplace=False)\n",
      "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (9): Dropout2d(p=0.25, inplace=False)\n",
      "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (13): Dropout2d(p=0.25, inplace=False)\n",
      "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (adv_layer): Linear(in_features=8192, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "    \n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)\n",
    "\n",
    "#from torchsummary import summary\n",
    "#summary(netD, input_size = (3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions and Optimizers\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "With $D$ and $G$ setup, we can specify how they learn\n",
    "through the loss functions and optimizers. We will use the Binary Cross\n",
    "Entropy loss\n",
    "(`BCELoss <https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss>`__)\n",
    "function which is defined in PyTorch as:\n",
    "\n",
    "\\begin{align}\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]\\end{align}\n",
    "\n",
    "Notice how this function provides the calculation of both log components\n",
    "in the objective function (i.e. $log(D(x))$ and\n",
    "$log(1-D(G(z)))$). We can specify what part of the BCE equation to\n",
    "use with the $y$ input. This is accomplished in the training loop\n",
    "which is coming up soon, but it is important to understand how we can\n",
    "choose which component we wish to calculate just by changing $y$\n",
    "(i.e. GT labels).\n",
    "\n",
    "Next, we define our real label as 1 and the fake label as 0. These\n",
    "labels will be used when calculating the losses of $D$ and\n",
    "$G$, and this is also the convention used in the original GAN\n",
    "paper. Finally, we set up two separate optimizers, one for $D$ and\n",
    "one for $G$. As specified in the DCGAN paper, both are Adam\n",
    "optimizers with learning rate 0.0002 and Beta1 = 0.5. For keeping track\n",
    "of the generator’s learning progression, we will generate a fixed batch\n",
    "of latent vectors that are drawn from a Gaussian distribution\n",
    "(i.e. fixed_noise) . In the training loop, we will periodically input\n",
    "this fixed_noise into $G$, and over the iterations we will see\n",
    "images form out of the noise.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 100, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Initialize BCELoss function\n",
    "#criterion = nn.BCELoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(128, nz, 1, 1, device=device)\n",
    "print(fixed_noise.shape)\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "~~~~~~~~\n",
    "\n",
    "Finally, now that we have all of the parts of the GAN framework defined,\n",
    "we can train it. Be mindful that training GANs is somewhat of an art\n",
    "form, as incorrect hyperparameter settings lead to mode collapse with\n",
    "little explanation of what went wrong. Here, we will closely follow\n",
    "Algorithm 1 from Goodfellow’s paper, while abiding by some of the best\n",
    "practices shown in `ganhacks <https://github.com/soumith/ganhacks>`__.\n",
    "Namely, we will “construct different mini-batches for real and fake”\n",
    "images, and also adjust G’s objective function to maximize\n",
    "$logD(G(z))$. Training is split up into two main parts. Part 1\n",
    "updates the Discriminator and Part 2 updates the Generator.\n",
    "\n",
    "**Part 1 - Train the Discriminator**\n",
    "\n",
    "Recall, the goal of training the discriminator is to maximize the\n",
    "probability of correctly classifying a given input as real or fake. In\n",
    "terms of Goodfellow, we wish to “update the discriminator by ascending\n",
    "its stochastic gradient”. Practically, we want to maximize\n",
    "$log(D(x)) + log(1-D(G(z)))$. Due to the separate mini-batch\n",
    "suggestion from ganhacks, we will calculate this in two steps. First, we\n",
    "will construct a batch of real samples from the training set, forward\n",
    "pass through $D$, calculate the loss ($log(D(x))$), then\n",
    "calculate the gradients in a backward pass. Secondly, we will construct\n",
    "a batch of fake samples with the current generator, forward pass this\n",
    "batch through $D$, calculate the loss ($log(1-D(G(z)))$),\n",
    "and *accumulate* the gradients with a backward pass. Now, with the\n",
    "gradients accumulated from both the all-real and all-fake batches, we\n",
    "call a step of the Discriminator’s optimizer.\n",
    "\n",
    "**Part 2 - Train the Generator**\n",
    "\n",
    "As stated in the original paper, we want to train the Generator by\n",
    "minimizing $log(1-D(G(z)))$ in an effort to generate better fakes.\n",
    "As mentioned, this was shown by Goodfellow to not provide sufficient\n",
    "gradients, especially early in the learning process. As a fix, we\n",
    "instead wish to maximize $log(D(G(z)))$. In the code we accomplish\n",
    "this by: classifying the Generator output from Part 1 with the\n",
    "Discriminator, computing G’s loss *using real labels as GT*, computing\n",
    "G’s gradients in a backward pass, and finally updating G’s parameters\n",
    "with an optimizer step. It may seem counter-intuitive to use the real\n",
    "labels as GT labels for the loss function, but this allows us to use the\n",
    "$log(x)$ part of the BCELoss (rather than the $log(1-x)$\n",
    "part) which is exactly what we want.\n",
    "\n",
    "Finally, we will do some statistic reporting and at the end of each\n",
    "epoch we will push our fixed_noise batch through the generator to\n",
    "visually track the progress of G’s training. The training statistics\n",
    "reported are:\n",
    "\n",
    "-  **Loss_D** - discriminator loss calculated as the sum of losses for\n",
    "   the all real and all fake batches ($log(D(x)) + log(D(G(z)))$).\n",
    "-  **Loss_G** - generator loss calculated as $log(D(G(z)))$\n",
    "-  **D(x)** - the average output (across the batch) of the discriminator\n",
    "   for the all real batch. This should start close to 1 then\n",
    "   theoretically converge to 0.5 when G gets better. Think about why\n",
    "   this is.\n",
    "-  **D(G(z))** - average discriminator outputs for the all fake batch.\n",
    "   The first number is before D is updated and the second number is\n",
    "   after D is updated. These numbers should start near 0 and converge to\n",
    "   0.5 as G gets better. Think about why this is.\n",
    "\n",
    "**Note:** This step might take a while, depending on how many epochs you\n",
    "run and if you removed some data from the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        \n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "        \n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=0, normalize=True))\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/150][0/539]\tLoss_D: 0.4985\tLoss_G: 0.9972\n",
      "[0/150][50/539]\tLoss_D: 0.2170\tLoss_G: 0.2816\n",
      "[0/150][100/539]\tLoss_D: 0.2602\tLoss_G: 0.2400\n",
      "[0/150][150/539]\tLoss_D: 0.2557\tLoss_G: 0.2547\n",
      "[0/150][200/539]\tLoss_D: 0.2521\tLoss_G: 0.2558\n",
      "[0/150][250/539]\tLoss_D: 0.2536\tLoss_G: 0.2539\n",
      "[0/150][300/539]\tLoss_D: 0.2500\tLoss_G: 0.2515\n",
      "[0/150][350/539]\tLoss_D: 0.2498\tLoss_G: 0.2490\n",
      "[0/150][400/539]\tLoss_D: 0.2517\tLoss_G: 0.2474\n",
      "[0/150][450/539]\tLoss_D: 0.2492\tLoss_G: 0.2443\n",
      "[0/150][500/539]\tLoss_D: 0.2496\tLoss_G: 0.2497\n",
      "[1/150][0/539]\tLoss_D: 0.2233\tLoss_G: 0.2626\n",
      "[1/150][50/539]\tLoss_D: 0.2778\tLoss_G: 0.3823\n",
      "[1/150][100/539]\tLoss_D: 0.3303\tLoss_G: 0.4195\n",
      "[1/150][150/539]\tLoss_D: 0.3090\tLoss_G: 0.3901\n",
      "[1/150][200/539]\tLoss_D: 0.4425\tLoss_G: 0.5207\n",
      "[1/150][250/539]\tLoss_D: 0.2620\tLoss_G: 0.3964\n",
      "[1/150][300/539]\tLoss_D: 0.4001\tLoss_G: 0.2589\n",
      "[1/150][350/539]\tLoss_D: 0.2338\tLoss_G: 0.3282\n",
      "[1/150][400/539]\tLoss_D: 0.2556\tLoss_G: 0.1956\n",
      "[1/150][450/539]\tLoss_D: 0.2388\tLoss_G: 0.2174\n",
      "[1/150][500/539]\tLoss_D: 0.3090\tLoss_G: 0.2412\n",
      "[2/150][0/539]\tLoss_D: 0.2453\tLoss_G: 0.3710\n",
      "[2/150][50/539]\tLoss_D: 0.1670\tLoss_G: 0.2082\n",
      "[2/150][100/539]\tLoss_D: 0.3241\tLoss_G: 0.3728\n",
      "[2/150][150/539]\tLoss_D: 0.2197\tLoss_G: 0.3575\n",
      "[2/150][200/539]\tLoss_D: 0.2388\tLoss_G: 0.5545\n",
      "[2/150][250/539]\tLoss_D: 0.2977\tLoss_G: 0.4170\n",
      "[2/150][300/539]\tLoss_D: 0.2334\tLoss_G: 0.3527\n",
      "[2/150][350/539]\tLoss_D: 0.2595\tLoss_G: 0.4340\n",
      "[2/150][400/539]\tLoss_D: 0.2394\tLoss_G: 0.3291\n",
      "[2/150][450/539]\tLoss_D: 0.2618\tLoss_G: 0.3399\n",
      "[2/150][500/539]\tLoss_D: 0.2639\tLoss_G: 0.2039\n",
      "[3/150][0/539]\tLoss_D: 0.1895\tLoss_G: 0.3174\n",
      "[3/150][50/539]\tLoss_D: 0.2549\tLoss_G: 0.1597\n",
      "[3/150][100/539]\tLoss_D: 0.2405\tLoss_G: 0.2057\n",
      "[3/150][150/539]\tLoss_D: 0.2860\tLoss_G: 0.2941\n",
      "[3/150][200/539]\tLoss_D: 0.2354\tLoss_G: 0.2314\n",
      "[3/150][250/539]\tLoss_D: 0.2886\tLoss_G: 0.2698\n",
      "[3/150][300/539]\tLoss_D: 0.2155\tLoss_G: 0.2654\n",
      "[3/150][350/539]\tLoss_D: 0.2350\tLoss_G: 0.3048\n",
      "[3/150][400/539]\tLoss_D: 0.2582\tLoss_G: 0.2138\n",
      "[3/150][450/539]\tLoss_D: 0.2410\tLoss_G: 0.2345\n",
      "[3/150][500/539]\tLoss_D: 0.2412\tLoss_G: 0.2929\n",
      "[4/150][0/539]\tLoss_D: 0.2670\tLoss_G: 0.2356\n",
      "[4/150][50/539]\tLoss_D: 0.2600\tLoss_G: 0.2474\n",
      "[4/150][100/539]\tLoss_D: 0.2561\tLoss_G: 0.2412\n",
      "[4/150][150/539]\tLoss_D: 0.2231\tLoss_G: 0.2671\n",
      "[4/150][200/539]\tLoss_D: 0.2443\tLoss_G: 0.2545\n",
      "[4/150][250/539]\tLoss_D: 0.2482\tLoss_G: 0.2485\n",
      "[4/150][300/539]\tLoss_D: 0.2282\tLoss_G: 0.2547\n",
      "[4/150][350/539]\tLoss_D: 0.2446\tLoss_G: 0.2600\n",
      "[4/150][400/539]\tLoss_D: 0.2512\tLoss_G: 0.2739\n",
      "[4/150][450/539]\tLoss_D: 0.2502\tLoss_G: 0.2490\n",
      "[4/150][500/539]\tLoss_D: 0.2345\tLoss_G: 0.2492\n",
      "[5/150][0/539]\tLoss_D: 0.2821\tLoss_G: 0.2681\n",
      "[5/150][50/539]\tLoss_D: 0.2960\tLoss_G: 0.2019\n",
      "[5/150][100/539]\tLoss_D: 0.1595\tLoss_G: 0.2749\n",
      "[5/150][150/539]\tLoss_D: 0.2425\tLoss_G: 0.2293\n",
      "[5/150][200/539]\tLoss_D: 0.2567\tLoss_G: 0.2563\n",
      "[5/150][250/539]\tLoss_D: 0.2366\tLoss_G: 0.3427\n",
      "[5/150][300/539]\tLoss_D: 0.2271\tLoss_G: 0.2809\n",
      "[5/150][350/539]\tLoss_D: 0.1953\tLoss_G: 0.2492\n",
      "[5/150][400/539]\tLoss_D: 0.2546\tLoss_G: 0.2615\n",
      "[5/150][450/539]\tLoss_D: 0.2825\tLoss_G: 0.2261\n",
      "[5/150][500/539]\tLoss_D: 0.2547\tLoss_G: 0.2626\n",
      "[6/150][0/539]\tLoss_D: 0.2098\tLoss_G: 0.2169\n",
      "[6/150][50/539]\tLoss_D: 0.2661\tLoss_G: 0.2395\n",
      "[6/150][100/539]\tLoss_D: 0.2508\tLoss_G: 0.3012\n",
      "[6/150][150/539]\tLoss_D: 0.2781\tLoss_G: 0.3288\n",
      "[6/150][200/539]\tLoss_D: 0.2510\tLoss_G: 0.2800\n",
      "[6/150][250/539]\tLoss_D: 0.2510\tLoss_G: 0.2457\n",
      "[6/150][300/539]\tLoss_D: 0.2468\tLoss_G: 0.2585\n",
      "[6/150][350/539]\tLoss_D: 0.2229\tLoss_G: 0.3056\n",
      "[6/150][400/539]\tLoss_D: 0.2026\tLoss_G: 0.2736\n",
      "[6/150][450/539]\tLoss_D: 0.2310\tLoss_G: 0.1828\n",
      "[6/150][500/539]\tLoss_D: 0.2651\tLoss_G: 0.2546\n",
      "[7/150][0/539]\tLoss_D: 0.2624\tLoss_G: 0.3745\n",
      "[7/150][50/539]\tLoss_D: 0.2948\tLoss_G: 0.2807\n",
      "[7/150][100/539]\tLoss_D: 0.3927\tLoss_G: 0.1623\n",
      "[7/150][150/539]\tLoss_D: 0.2702\tLoss_G: 0.2630\n",
      "[7/150][200/539]\tLoss_D: 0.2002\tLoss_G: 0.2871\n",
      "[7/150][250/539]\tLoss_D: 0.1830\tLoss_G: 0.3750\n",
      "[7/150][300/539]\tLoss_D: 0.1771\tLoss_G: 0.3371\n",
      "[7/150][350/539]\tLoss_D: 0.3837\tLoss_G: 0.2306\n",
      "[7/150][400/539]\tLoss_D: 0.2576\tLoss_G: 0.2272\n",
      "[7/150][450/539]\tLoss_D: 0.3266\tLoss_G: 0.3717\n",
      "[7/150][500/539]\tLoss_D: 0.2483\tLoss_G: 0.2955\n",
      "[8/150][0/539]\tLoss_D: 0.3104\tLoss_G: 0.2503\n",
      "[8/150][50/539]\tLoss_D: 0.2451\tLoss_G: 0.2362\n",
      "[8/150][100/539]\tLoss_D: 0.2285\tLoss_G: 0.3659\n",
      "[8/150][150/539]\tLoss_D: 0.2370\tLoss_G: 0.2823\n",
      "[8/150][200/539]\tLoss_D: 0.1873\tLoss_G: 0.2383\n",
      "[8/150][250/539]\tLoss_D: 0.2077\tLoss_G: 0.7523\n",
      "[8/150][300/539]\tLoss_D: 0.2478\tLoss_G: 0.3060\n",
      "[8/150][350/539]\tLoss_D: 0.3152\tLoss_G: 0.3861\n",
      "[8/150][400/539]\tLoss_D: 0.1651\tLoss_G: 0.3929\n",
      "[8/150][450/539]\tLoss_D: 0.2129\tLoss_G: 0.3275\n",
      "[8/150][500/539]\tLoss_D: 0.2158\tLoss_G: 0.2897\n",
      "[9/150][0/539]\tLoss_D: 0.3033\tLoss_G: 0.3295\n",
      "[9/150][50/539]\tLoss_D: 0.3397\tLoss_G: 0.2085\n",
      "[9/150][100/539]\tLoss_D: 0.1530\tLoss_G: 0.2024\n",
      "[9/150][150/539]\tLoss_D: 0.2786\tLoss_G: 0.2510\n",
      "[9/150][200/539]\tLoss_D: 0.2852\tLoss_G: 0.2972\n",
      "[9/150][250/539]\tLoss_D: 0.1863\tLoss_G: 0.3682\n",
      "[9/150][300/539]\tLoss_D: 0.2191\tLoss_G: 0.1487\n",
      "[9/150][350/539]\tLoss_D: 0.1027\tLoss_G: 0.5265\n",
      "[9/150][400/539]\tLoss_D: 0.2129\tLoss_G: 0.3666\n",
      "[9/150][450/539]\tLoss_D: 0.2455\tLoss_G: 0.2839\n",
      "[9/150][500/539]\tLoss_D: 0.2672\tLoss_G: 0.2550\n",
      "[10/150][0/539]\tLoss_D: 0.3094\tLoss_G: 0.4659\n",
      "[10/150][50/539]\tLoss_D: 0.2119\tLoss_G: 0.2302\n",
      "[10/150][100/539]\tLoss_D: 0.2577\tLoss_G: 0.2886\n",
      "[10/150][150/539]\tLoss_D: 0.2925\tLoss_G: 0.1677\n",
      "[10/150][200/539]\tLoss_D: 0.4455\tLoss_G: 0.2342\n",
      "[10/150][250/539]\tLoss_D: 0.2503\tLoss_G: 0.2539\n",
      "[10/150][300/539]\tLoss_D: 0.2323\tLoss_G: 0.2644\n",
      "[10/150][350/539]\tLoss_D: 0.2217\tLoss_G: 0.2855\n",
      "[10/150][400/539]\tLoss_D: 0.2393\tLoss_G: 0.2520\n",
      "[10/150][450/539]\tLoss_D: 0.2536\tLoss_G: 0.2437\n",
      "[10/150][500/539]\tLoss_D: 0.2625\tLoss_G: 0.2585\n",
      "[11/150][0/539]\tLoss_D: 0.2460\tLoss_G: 0.3056\n",
      "[11/150][50/539]\tLoss_D: 0.2047\tLoss_G: 0.2704\n",
      "[11/150][100/539]\tLoss_D: 0.2927\tLoss_G: 0.3153\n",
      "[11/150][150/539]\tLoss_D: 0.1835\tLoss_G: 0.2642\n",
      "[11/150][200/539]\tLoss_D: 0.2088\tLoss_G: 0.2920\n",
      "[11/150][250/539]\tLoss_D: 0.3320\tLoss_G: 0.3015\n",
      "[11/150][300/539]\tLoss_D: 0.2429\tLoss_G: 0.2056\n",
      "[11/150][350/539]\tLoss_D: 0.1820\tLoss_G: 0.3737\n",
      "[11/150][400/539]\tLoss_D: 0.0740\tLoss_G: 0.3077\n",
      "[11/150][450/539]\tLoss_D: 0.2009\tLoss_G: 0.3581\n",
      "[11/150][500/539]\tLoss_D: 0.3811\tLoss_G: 0.1435\n",
      "[12/150][0/539]\tLoss_D: 0.1221\tLoss_G: 0.4998\n",
      "[12/150][50/539]\tLoss_D: 0.1275\tLoss_G: 0.3199\n",
      "[12/150][100/539]\tLoss_D: 0.3166\tLoss_G: 0.2413\n",
      "[12/150][150/539]\tLoss_D: 0.1281\tLoss_G: 0.3866\n",
      "[12/150][200/539]\tLoss_D: 0.1950\tLoss_G: 0.3600\n",
      "[12/150][250/539]\tLoss_D: 0.1346\tLoss_G: 0.4617\n",
      "[12/150][300/539]\tLoss_D: 0.2913\tLoss_G: 0.0689\n",
      "[12/150][350/539]\tLoss_D: 0.2410\tLoss_G: 0.2575\n",
      "[12/150][400/539]\tLoss_D: 0.0592\tLoss_G: 0.1032\n",
      "[12/150][450/539]\tLoss_D: 0.3171\tLoss_G: 0.3556\n",
      "[12/150][500/539]\tLoss_D: 0.2041\tLoss_G: 0.3111\n",
      "[13/150][0/539]\tLoss_D: 0.2591\tLoss_G: 0.1650\n",
      "[13/150][50/539]\tLoss_D: 0.3210\tLoss_G: 0.3235\n",
      "[13/150][100/539]\tLoss_D: 0.2917\tLoss_G: 0.2611\n",
      "[13/150][150/539]\tLoss_D: 0.0685\tLoss_G: 0.3729\n",
      "[13/150][200/539]\tLoss_D: 0.0903\tLoss_G: 0.4583\n",
      "[13/150][250/539]\tLoss_D: 0.0894\tLoss_G: 0.3838\n",
      "[13/150][300/539]\tLoss_D: 0.1350\tLoss_G: 0.2582\n",
      "[13/150][350/539]\tLoss_D: 0.3054\tLoss_G: 0.2332\n",
      "[13/150][400/539]\tLoss_D: 0.1979\tLoss_G: 0.3267\n",
      "[13/150][450/539]\tLoss_D: 0.0853\tLoss_G: 0.1930\n",
      "[13/150][500/539]\tLoss_D: 0.2909\tLoss_G: 0.2144\n",
      "[14/150][0/539]\tLoss_D: 0.4215\tLoss_G: 0.4712\n",
      "[14/150][50/539]\tLoss_D: 0.1936\tLoss_G: 0.5638\n",
      "[14/150][100/539]\tLoss_D: 0.2229\tLoss_G: 0.3334\n",
      "[14/150][150/539]\tLoss_D: 0.3180\tLoss_G: 0.2300\n",
      "[14/150][200/539]\tLoss_D: 0.2557\tLoss_G: 0.2403\n",
      "[14/150][250/539]\tLoss_D: 0.1383\tLoss_G: 0.3450\n",
      "[14/150][300/539]\tLoss_D: 0.1861\tLoss_G: 0.2989\n",
      "[14/150][350/539]\tLoss_D: 0.2043\tLoss_G: 0.3326\n",
      "[14/150][400/539]\tLoss_D: 0.1473\tLoss_G: 0.2736\n",
      "[14/150][450/539]\tLoss_D: 0.1799\tLoss_G: 0.1825\n",
      "[14/150][500/539]\tLoss_D: 0.2516\tLoss_G: 0.3246\n",
      "[15/150][0/539]\tLoss_D: 0.2489\tLoss_G: 0.3553\n",
      "[15/150][50/539]\tLoss_D: 0.3301\tLoss_G: 0.2626\n",
      "[15/150][100/539]\tLoss_D: 0.2146\tLoss_G: 0.2407\n",
      "[15/150][150/539]\tLoss_D: 0.2885\tLoss_G: 0.3305\n",
      "[15/150][200/539]\tLoss_D: 0.2598\tLoss_G: 0.2276\n",
      "[15/150][250/539]\tLoss_D: 0.3189\tLoss_G: 0.2579\n",
      "[15/150][300/539]\tLoss_D: 0.2285\tLoss_G: 0.2342\n",
      "[15/150][350/539]\tLoss_D: 0.2490\tLoss_G: 0.2146\n",
      "[15/150][400/539]\tLoss_D: 0.2621\tLoss_G: 0.2825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/150][450/539]\tLoss_D: 0.3179\tLoss_G: 0.1956\n",
      "[15/150][500/539]\tLoss_D: 0.2668\tLoss_G: 0.2302\n",
      "[16/150][0/539]\tLoss_D: 0.2332\tLoss_G: 0.2781\n",
      "[16/150][50/539]\tLoss_D: 0.2865\tLoss_G: 0.2793\n",
      "[16/150][100/539]\tLoss_D: 0.2706\tLoss_G: 0.2569\n",
      "[16/150][150/539]\tLoss_D: 0.2502\tLoss_G: 0.2975\n",
      "[16/150][200/539]\tLoss_D: 0.2456\tLoss_G: 0.2523\n",
      "[16/150][250/539]\tLoss_D: 0.1403\tLoss_G: 0.3043\n",
      "[16/150][300/539]\tLoss_D: 0.2262\tLoss_G: 0.3096\n",
      "[16/150][350/539]\tLoss_D: 0.2791\tLoss_G: 0.3097\n",
      "[16/150][400/539]\tLoss_D: 0.2407\tLoss_G: 0.2261\n",
      "[16/150][450/539]\tLoss_D: 0.2361\tLoss_G: 0.2636\n",
      "[16/150][500/539]\tLoss_D: 0.2458\tLoss_G: 0.2260\n",
      "[17/150][0/539]\tLoss_D: 0.2542\tLoss_G: 0.3097\n",
      "[17/150][50/539]\tLoss_D: 0.2550\tLoss_G: 0.3097\n",
      "[17/150][100/539]\tLoss_D: 0.2765\tLoss_G: 0.2029\n",
      "[17/150][150/539]\tLoss_D: 0.2615\tLoss_G: 0.2566\n",
      "[17/150][200/539]\tLoss_D: 0.2648\tLoss_G: 0.2060\n",
      "[17/150][250/539]\tLoss_D: 0.2390\tLoss_G: 0.2705\n",
      "[17/150][300/539]\tLoss_D: 0.2367\tLoss_G: 0.3864\n",
      "[17/150][350/539]\tLoss_D: 0.2352\tLoss_G: 0.3011\n",
      "[17/150][400/539]\tLoss_D: 0.1953\tLoss_G: 0.2756\n",
      "[17/150][450/539]\tLoss_D: 0.1794\tLoss_G: 0.2462\n",
      "[17/150][500/539]\tLoss_D: 0.2425\tLoss_G: 0.2481\n",
      "[18/150][0/539]\tLoss_D: 0.2737\tLoss_G: 0.1385\n",
      "[18/150][50/539]\tLoss_D: 0.2436\tLoss_G: 0.3768\n",
      "[18/150][100/539]\tLoss_D: 0.2968\tLoss_G: 0.4505\n",
      "[18/150][150/539]\tLoss_D: 0.2020\tLoss_G: 0.2590\n",
      "[18/150][200/539]\tLoss_D: 0.2337\tLoss_G: 0.2403\n",
      "[18/150][250/539]\tLoss_D: 0.2544\tLoss_G: 0.2333\n",
      "[18/150][300/539]\tLoss_D: 0.2529\tLoss_G: 0.2649\n",
      "[18/150][350/539]\tLoss_D: 0.2260\tLoss_G: 0.2752\n",
      "[18/150][400/539]\tLoss_D: 0.2410\tLoss_G: 0.2414\n",
      "[18/150][450/539]\tLoss_D: 0.2692\tLoss_G: 0.2840\n",
      "[18/150][500/539]\tLoss_D: 0.2234\tLoss_G: 0.2849\n",
      "[19/150][0/539]\tLoss_D: 0.2293\tLoss_G: 0.2815\n",
      "[19/150][50/539]\tLoss_D: 0.2513\tLoss_G: 0.2757\n",
      "[19/150][100/539]\tLoss_D: 0.2432\tLoss_G: 0.2218\n",
      "[19/150][150/539]\tLoss_D: 0.2404\tLoss_G: 0.2205\n",
      "[19/150][200/539]\tLoss_D: 0.2403\tLoss_G: 0.2644\n",
      "[19/150][250/539]\tLoss_D: 0.2393\tLoss_G: 0.3097\n",
      "[19/150][300/539]\tLoss_D: 0.2581\tLoss_G: 0.2233\n",
      "[19/150][350/539]\tLoss_D: 0.2285\tLoss_G: 0.2523\n",
      "[19/150][400/539]\tLoss_D: 0.2561\tLoss_G: 0.1721\n",
      "[19/150][450/539]\tLoss_D: 0.2542\tLoss_G: 0.1920\n",
      "[19/150][500/539]\tLoss_D: 0.2944\tLoss_G: 0.0835\n",
      "[20/150][0/539]\tLoss_D: 0.2608\tLoss_G: 0.2259\n",
      "[20/150][50/539]\tLoss_D: 0.2217\tLoss_G: 0.2620\n",
      "[20/150][100/539]\tLoss_D: 0.2467\tLoss_G: 0.1228\n",
      "[20/150][150/539]\tLoss_D: 0.2896\tLoss_G: 0.3016\n",
      "[20/150][200/539]\tLoss_D: 0.2580\tLoss_G: 0.2766\n",
      "[20/150][250/539]\tLoss_D: 0.2329\tLoss_G: 0.2971\n",
      "[20/150][300/539]\tLoss_D: 0.2407\tLoss_G: 0.2086\n",
      "[20/150][350/539]\tLoss_D: 0.2572\tLoss_G: 0.2390\n",
      "[20/150][400/539]\tLoss_D: 0.2489\tLoss_G: 0.2669\n",
      "[20/150][450/539]\tLoss_D: 0.2509\tLoss_G: 0.2276\n",
      "[20/150][500/539]\tLoss_D: 0.2483\tLoss_G: 0.1588\n",
      "[21/150][0/539]\tLoss_D: 0.2016\tLoss_G: 0.2311\n",
      "[21/150][50/539]\tLoss_D: 0.2405\tLoss_G: 0.2741\n",
      "[21/150][100/539]\tLoss_D: 0.2351\tLoss_G: 0.3311\n",
      "[21/150][150/539]\tLoss_D: 0.2441\tLoss_G: 0.2339\n",
      "[21/150][200/539]\tLoss_D: 0.2845\tLoss_G: 0.2573\n",
      "[21/150][250/539]\tLoss_D: 0.2837\tLoss_G: 0.3806\n",
      "[21/150][300/539]\tLoss_D: 0.2476\tLoss_G: 0.3469\n",
      "[21/150][350/539]\tLoss_D: 0.2385\tLoss_G: 0.3860\n",
      "[21/150][400/539]\tLoss_D: 0.2218\tLoss_G: 0.2592\n",
      "[21/150][450/539]\tLoss_D: 0.2346\tLoss_G: 0.2823\n",
      "[21/150][500/539]\tLoss_D: 0.2175\tLoss_G: 0.2032\n",
      "[22/150][0/539]\tLoss_D: 0.1569\tLoss_G: 0.2834\n",
      "[22/150][50/539]\tLoss_D: 0.3938\tLoss_G: 0.6636\n",
      "[22/150][100/539]\tLoss_D: 0.1939\tLoss_G: 0.1976\n",
      "[22/150][150/539]\tLoss_D: 0.2347\tLoss_G: 0.2298\n",
      "[22/150][200/539]\tLoss_D: 0.2114\tLoss_G: 0.1940\n",
      "[22/150][250/539]\tLoss_D: 0.3389\tLoss_G: 0.3104\n",
      "[22/150][300/539]\tLoss_D: 0.2943\tLoss_G: 0.2926\n",
      "[22/150][350/539]\tLoss_D: 0.2279\tLoss_G: 0.3226\n",
      "[22/150][400/539]\tLoss_D: 0.2344\tLoss_G: 0.4160\n",
      "[22/150][450/539]\tLoss_D: 0.2671\tLoss_G: 0.1203\n",
      "[22/150][500/539]\tLoss_D: 0.2272\tLoss_G: 0.2217\n",
      "[23/150][0/539]\tLoss_D: 0.2132\tLoss_G: 0.2442\n",
      "[23/150][50/539]\tLoss_D: 0.2378\tLoss_G: 0.2217\n",
      "[23/150][100/539]\tLoss_D: 0.2222\tLoss_G: 0.2606\n",
      "[23/150][150/539]\tLoss_D: 0.2453\tLoss_G: 0.1843\n",
      "[23/150][200/539]\tLoss_D: 0.2743\tLoss_G: 0.1994\n",
      "[23/150][250/539]\tLoss_D: 0.1971\tLoss_G: 0.2178\n",
      "[23/150][300/539]\tLoss_D: 0.2569\tLoss_G: 0.2122\n",
      "[23/150][350/539]\tLoss_D: 0.2393\tLoss_G: 0.2968\n",
      "[23/150][400/539]\tLoss_D: 0.2023\tLoss_G: 0.2920\n",
      "[23/150][450/539]\tLoss_D: 0.2302\tLoss_G: 0.2938\n",
      "[23/150][500/539]\tLoss_D: 0.3190\tLoss_G: 0.2885\n",
      "[24/150][0/539]\tLoss_D: 0.2510\tLoss_G: 0.2661\n",
      "[24/150][50/539]\tLoss_D: 0.2610\tLoss_G: 0.2110\n",
      "[24/150][100/539]\tLoss_D: 0.2151\tLoss_G: 0.3262\n",
      "[24/150][150/539]\tLoss_D: 0.2555\tLoss_G: 0.2963\n",
      "[24/150][200/539]\tLoss_D: 0.2454\tLoss_G: 0.2907\n",
      "[24/150][250/539]\tLoss_D: 0.2301\tLoss_G: 0.2337\n",
      "[24/150][300/539]\tLoss_D: 0.3741\tLoss_G: 0.2767\n",
      "[24/150][350/539]\tLoss_D: 0.2427\tLoss_G: 0.1821\n",
      "[24/150][400/539]\tLoss_D: 0.2307\tLoss_G: 0.2790\n",
      "[24/150][450/539]\tLoss_D: 0.2625\tLoss_G: 0.2300\n",
      "[24/150][500/539]\tLoss_D: 0.1274\tLoss_G: 0.3133\n",
      "[25/150][0/539]\tLoss_D: 0.2465\tLoss_G: 0.3256\n",
      "[25/150][50/539]\tLoss_D: 0.2366\tLoss_G: 0.1915\n",
      "[25/150][100/539]\tLoss_D: 0.1995\tLoss_G: 0.3052\n",
      "[25/150][150/539]\tLoss_D: 0.1797\tLoss_G: 0.2994\n",
      "[25/150][200/539]\tLoss_D: 0.2559\tLoss_G: 0.1808\n",
      "[25/150][250/539]\tLoss_D: 0.2240\tLoss_G: 0.2372\n",
      "[25/150][300/539]\tLoss_D: 0.4015\tLoss_G: 0.2598\n",
      "[25/150][350/539]\tLoss_D: 0.2722\tLoss_G: 0.2504\n",
      "[25/150][400/539]\tLoss_D: 0.2542\tLoss_G: 0.2871\n",
      "[25/150][450/539]\tLoss_D: 0.2906\tLoss_G: 0.2598\n",
      "[25/150][500/539]\tLoss_D: 0.2158\tLoss_G: 0.2610\n",
      "[26/150][0/539]\tLoss_D: 0.2171\tLoss_G: 0.2884\n",
      "[26/150][50/539]\tLoss_D: 0.2390\tLoss_G: 0.2376\n",
      "[26/150][100/539]\tLoss_D: 0.2573\tLoss_G: 0.2343\n",
      "[26/150][150/539]\tLoss_D: 0.2645\tLoss_G: 0.2648\n",
      "[26/150][200/539]\tLoss_D: 0.2120\tLoss_G: 0.2449\n",
      "[26/150][250/539]\tLoss_D: 0.2481\tLoss_G: 0.2475\n",
      "[26/150][300/539]\tLoss_D: 0.2223\tLoss_G: 0.2876\n",
      "[26/150][350/539]\tLoss_D: 0.2602\tLoss_G: 0.2393\n",
      "[26/150][400/539]\tLoss_D: 0.2597\tLoss_G: 0.3463\n",
      "[26/150][450/539]\tLoss_D: 0.2083\tLoss_G: 0.2440\n",
      "[26/150][500/539]\tLoss_D: 0.2173\tLoss_G: 0.2974\n",
      "[27/150][0/539]\tLoss_D: 0.2619\tLoss_G: 0.2308\n",
      "[27/150][50/539]\tLoss_D: 0.2500\tLoss_G: 0.2350\n",
      "[27/150][100/539]\tLoss_D: 0.3207\tLoss_G: 0.2280\n",
      "[27/150][150/539]\tLoss_D: 0.3105\tLoss_G: 0.3293\n",
      "[27/150][200/539]\tLoss_D: 0.2792\tLoss_G: 0.2000\n",
      "[27/150][250/539]\tLoss_D: 0.2744\tLoss_G: 0.2806\n",
      "[27/150][300/539]\tLoss_D: 0.2321\tLoss_G: 0.1953\n",
      "[27/150][350/539]\tLoss_D: 0.2538\tLoss_G: 0.2924\n",
      "[27/150][400/539]\tLoss_D: 0.2515\tLoss_G: 0.2170\n",
      "[27/150][450/539]\tLoss_D: 0.1956\tLoss_G: 0.3651\n",
      "[27/150][500/539]\tLoss_D: 0.2692\tLoss_G: 0.1676\n",
      "[28/150][0/539]\tLoss_D: 0.2333\tLoss_G: 0.3084\n",
      "[28/150][50/539]\tLoss_D: 0.2736\tLoss_G: 0.3653\n",
      "[28/150][100/539]\tLoss_D: 0.2344\tLoss_G: 0.3629\n",
      "[28/150][150/539]\tLoss_D: 0.2255\tLoss_G: 0.3317\n",
      "[28/150][200/539]\tLoss_D: 0.2246\tLoss_G: 0.4592\n",
      "[28/150][250/539]\tLoss_D: 0.2493\tLoss_G: 0.2925\n",
      "[28/150][300/539]\tLoss_D: 0.2767\tLoss_G: 0.2418\n",
      "[28/150][350/539]\tLoss_D: 0.2317\tLoss_G: 0.2469\n",
      "[28/150][400/539]\tLoss_D: 0.4883\tLoss_G: 0.1583\n",
      "[28/150][450/539]\tLoss_D: 0.2177\tLoss_G: 0.1939\n",
      "[28/150][500/539]\tLoss_D: 0.2716\tLoss_G: 0.2686\n",
      "[29/150][0/539]\tLoss_D: 0.2611\tLoss_G: 0.2462\n",
      "[29/150][50/539]\tLoss_D: 0.2250\tLoss_G: 0.2632\n",
      "[29/150][100/539]\tLoss_D: 0.2492\tLoss_G: 0.2564\n",
      "[29/150][150/539]\tLoss_D: 0.2468\tLoss_G: 0.2751\n",
      "[29/150][200/539]\tLoss_D: 0.2321\tLoss_G: 0.2403\n",
      "[29/150][250/539]\tLoss_D: 0.1971\tLoss_G: 0.2783\n",
      "[29/150][300/539]\tLoss_D: 0.2346\tLoss_G: 0.2678\n",
      "[29/150][350/539]\tLoss_D: 0.2344\tLoss_G: 0.2398\n",
      "[29/150][400/539]\tLoss_D: 0.2587\tLoss_G: 0.2562\n",
      "[29/150][450/539]\tLoss_D: 0.2624\tLoss_G: 0.3135\n",
      "[29/150][500/539]\tLoss_D: 0.2382\tLoss_G: 0.2569\n",
      "[30/150][0/539]\tLoss_D: 0.2583\tLoss_G: 0.2458\n",
      "[30/150][50/539]\tLoss_D: 0.2378\tLoss_G: 0.2726\n",
      "[30/150][100/539]\tLoss_D: 0.2092\tLoss_G: 0.2420\n",
      "[30/150][150/539]\tLoss_D: 0.2431\tLoss_G: 0.2429\n",
      "[30/150][200/539]\tLoss_D: 0.2573\tLoss_G: 0.3193\n",
      "[30/150][250/539]\tLoss_D: 0.2505\tLoss_G: 0.3289\n",
      "[30/150][300/539]\tLoss_D: 0.2189\tLoss_G: 0.2681\n",
      "[30/150][350/539]\tLoss_D: 0.2579\tLoss_G: 0.2592\n",
      "[30/150][400/539]\tLoss_D: 0.2434\tLoss_G: 0.2536\n",
      "[30/150][450/539]\tLoss_D: 0.2282\tLoss_G: 0.2237\n",
      "[30/150][500/539]\tLoss_D: 0.2587\tLoss_G: 0.2661\n",
      "[31/150][0/539]\tLoss_D: 0.2490\tLoss_G: 0.2327\n",
      "[31/150][50/539]\tLoss_D: 0.2626\tLoss_G: 0.2294\n",
      "[31/150][100/539]\tLoss_D: 0.1964\tLoss_G: 0.2988\n",
      "[31/150][150/539]\tLoss_D: 0.2561\tLoss_G: 0.2850\n",
      "[31/150][200/539]\tLoss_D: 0.2503\tLoss_G: 0.2343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/150][250/539]\tLoss_D: 0.2162\tLoss_G: 0.1947\n",
      "[31/150][300/539]\tLoss_D: 0.2569\tLoss_G: 0.2556\n",
      "[31/150][350/539]\tLoss_D: 0.1799\tLoss_G: 0.3572\n",
      "[31/150][400/539]\tLoss_D: 0.2887\tLoss_G: 0.2460\n",
      "[31/150][450/539]\tLoss_D: 0.2907\tLoss_G: 0.2254\n",
      "[31/150][500/539]\tLoss_D: 0.3428\tLoss_G: 0.3857\n",
      "[32/150][0/539]\tLoss_D: 0.2476\tLoss_G: 0.2830\n",
      "[32/150][50/539]\tLoss_D: 0.2475\tLoss_G: 0.2591\n",
      "[32/150][100/539]\tLoss_D: 0.2324\tLoss_G: 0.2702\n",
      "[32/150][150/539]\tLoss_D: 0.2595\tLoss_G: 0.2571\n",
      "[32/150][200/539]\tLoss_D: 0.2503\tLoss_G: 0.2448\n",
      "[32/150][250/539]\tLoss_D: 0.1026\tLoss_G: 0.3141\n",
      "[32/150][300/539]\tLoss_D: 0.2696\tLoss_G: 0.1918\n",
      "[32/150][350/539]\tLoss_D: 0.2391\tLoss_G: 0.2396\n",
      "[32/150][400/539]\tLoss_D: 0.2031\tLoss_G: 0.3803\n",
      "[32/150][450/539]\tLoss_D: 0.3546\tLoss_G: 0.2342\n",
      "[32/150][500/539]\tLoss_D: 0.2498\tLoss_G: 0.3498\n",
      "[33/150][0/539]\tLoss_D: 0.2411\tLoss_G: 0.2004\n",
      "[33/150][50/539]\tLoss_D: 0.2297\tLoss_G: 0.2172\n",
      "[33/150][100/539]\tLoss_D: 0.2412\tLoss_G: 0.2774\n",
      "[33/150][150/539]\tLoss_D: 0.1780\tLoss_G: 0.2906\n",
      "[33/150][200/539]\tLoss_D: 0.2589\tLoss_G: 0.2295\n",
      "[33/150][250/539]\tLoss_D: 0.2461\tLoss_G: 0.2099\n",
      "[33/150][300/539]\tLoss_D: 0.2374\tLoss_G: 0.2283\n",
      "[33/150][350/539]\tLoss_D: 0.2436\tLoss_G: 0.2747\n",
      "[33/150][400/539]\tLoss_D: 0.2683\tLoss_G: 0.3360\n",
      "[33/150][450/539]\tLoss_D: 0.1989\tLoss_G: 0.2362\n",
      "[33/150][500/539]\tLoss_D: 0.2609\tLoss_G: 0.2401\n",
      "[34/150][0/539]\tLoss_D: 0.3714\tLoss_G: 0.1178\n",
      "[34/150][50/539]\tLoss_D: 0.2632\tLoss_G: 0.2933\n",
      "[34/150][100/539]\tLoss_D: 0.2569\tLoss_G: 0.2931\n",
      "[34/150][150/539]\tLoss_D: 0.2825\tLoss_G: 0.1824\n",
      "[34/150][200/539]\tLoss_D: 0.2881\tLoss_G: 0.2340\n",
      "[34/150][250/539]\tLoss_D: 0.1700\tLoss_G: 0.3443\n",
      "[34/150][300/539]\tLoss_D: 0.2300\tLoss_G: 0.3379\n",
      "[34/150][350/539]\tLoss_D: 0.2265\tLoss_G: 0.2609\n",
      "[34/150][400/539]\tLoss_D: 0.0973\tLoss_G: 0.2039\n",
      "[34/150][450/539]\tLoss_D: 0.2528\tLoss_G: 0.3132\n",
      "[34/150][500/539]\tLoss_D: 0.2706\tLoss_G: 0.3511\n",
      "[35/150][0/539]\tLoss_D: 0.1762\tLoss_G: 0.2742\n",
      "[35/150][50/539]\tLoss_D: 0.2119\tLoss_G: 0.2513\n",
      "[35/150][100/539]\tLoss_D: 0.2621\tLoss_G: 0.2915\n",
      "[35/150][150/539]\tLoss_D: 0.2498\tLoss_G: 0.3589\n",
      "[35/150][200/539]\tLoss_D: 0.2977\tLoss_G: 0.2463\n",
      "[35/150][250/539]\tLoss_D: 0.1602\tLoss_G: 0.3110\n",
      "[35/150][300/539]\tLoss_D: 0.2402\tLoss_G: 0.2132\n",
      "[35/150][350/539]\tLoss_D: 0.2091\tLoss_G: 0.2644\n",
      "[35/150][400/539]\tLoss_D: 0.2521\tLoss_G: 0.2354\n",
      "[35/150][450/539]\tLoss_D: 0.2272\tLoss_G: 0.2196\n",
      "[35/150][500/539]\tLoss_D: 0.2034\tLoss_G: 0.3570\n",
      "[36/150][0/539]\tLoss_D: 0.2620\tLoss_G: 0.2289\n",
      "[36/150][50/539]\tLoss_D: 0.2480\tLoss_G: 0.3055\n",
      "[36/150][100/539]\tLoss_D: 0.2975\tLoss_G: 0.1750\n",
      "[36/150][150/539]\tLoss_D: 0.2245\tLoss_G: 0.2738\n",
      "[36/150][200/539]\tLoss_D: 0.2700\tLoss_G: 0.2499\n",
      "[36/150][250/539]\tLoss_D: 0.2182\tLoss_G: 0.2525\n",
      "[36/150][300/539]\tLoss_D: 0.2572\tLoss_G: 0.2351\n",
      "[36/150][350/539]\tLoss_D: 0.2623\tLoss_G: 0.2195\n",
      "[36/150][400/539]\tLoss_D: 0.2326\tLoss_G: 0.2215\n",
      "[36/150][450/539]\tLoss_D: 0.2641\tLoss_G: 0.3950\n",
      "[36/150][500/539]\tLoss_D: 0.2858\tLoss_G: 0.1744\n",
      "[37/150][0/539]\tLoss_D: 0.2144\tLoss_G: 0.2809\n",
      "[37/150][50/539]\tLoss_D: 0.2591\tLoss_G: 0.2824\n",
      "[37/150][100/539]\tLoss_D: 0.2764\tLoss_G: 0.2583\n",
      "[37/150][150/539]\tLoss_D: 0.2003\tLoss_G: 0.2492\n",
      "[37/150][200/539]\tLoss_D: 0.2332\tLoss_G: 0.2535\n",
      "[37/150][250/539]\tLoss_D: 0.2167\tLoss_G: 0.2118\n",
      "[37/150][300/539]\tLoss_D: 0.2383\tLoss_G: 0.2621\n",
      "[37/150][350/539]\tLoss_D: 0.2485\tLoss_G: 0.2658\n",
      "[37/150][400/539]\tLoss_D: 0.2429\tLoss_G: 0.2624\n",
      "[37/150][450/539]\tLoss_D: 0.2035\tLoss_G: 0.2775\n",
      "[37/150][500/539]\tLoss_D: 0.2552\tLoss_G: 0.2390\n",
      "[38/150][0/539]\tLoss_D: 0.1823\tLoss_G: 0.2868\n",
      "[38/150][50/539]\tLoss_D: 0.2325\tLoss_G: 0.3306\n",
      "[38/150][100/539]\tLoss_D: 0.2329\tLoss_G: 0.2660\n",
      "[38/150][150/539]\tLoss_D: 0.2423\tLoss_G: 0.2243\n",
      "[38/150][200/539]\tLoss_D: 0.2504\tLoss_G: 0.2540\n",
      "[38/150][250/539]\tLoss_D: 0.2147\tLoss_G: 0.2432\n",
      "[38/150][300/539]\tLoss_D: 0.2124\tLoss_G: 0.2911\n",
      "[38/150][350/539]\tLoss_D: 0.2319\tLoss_G: 0.2756\n",
      "[38/150][400/539]\tLoss_D: 0.2811\tLoss_G: 0.2730\n",
      "[38/150][450/539]\tLoss_D: 0.2986\tLoss_G: 0.2740\n",
      "[38/150][500/539]\tLoss_D: 0.2637\tLoss_G: 0.2283\n",
      "[39/150][0/539]\tLoss_D: 0.2533\tLoss_G: 0.2498\n",
      "[39/150][50/539]\tLoss_D: 0.2477\tLoss_G: 0.3287\n",
      "[39/150][100/539]\tLoss_D: 0.2767\tLoss_G: 0.2856\n",
      "[39/150][150/539]\tLoss_D: 0.2086\tLoss_G: 0.2745\n",
      "[39/150][200/539]\tLoss_D: 0.2406\tLoss_G: 0.2679\n",
      "[39/150][250/539]\tLoss_D: 0.2591\tLoss_G: 0.3060\n",
      "[39/150][300/539]\tLoss_D: 0.2537\tLoss_G: 0.2512\n",
      "[39/150][350/539]\tLoss_D: 0.2346\tLoss_G: 0.3157\n",
      "[39/150][400/539]\tLoss_D: 0.3130\tLoss_G: 0.2463\n",
      "[39/150][450/539]\tLoss_D: 0.2627\tLoss_G: 0.2178\n",
      "[39/150][500/539]\tLoss_D: 0.2557\tLoss_G: 0.2068\n",
      "[40/150][0/539]\tLoss_D: 0.2207\tLoss_G: 0.2758\n",
      "[40/150][50/539]\tLoss_D: 0.2716\tLoss_G: 0.2236\n",
      "[40/150][100/539]\tLoss_D: 0.1380\tLoss_G: 0.2817\n",
      "[40/150][150/539]\tLoss_D: 0.2470\tLoss_G: 0.2757\n",
      "[40/150][200/539]\tLoss_D: 0.2945\tLoss_G: 0.1679\n",
      "[40/150][250/539]\tLoss_D: 0.2296\tLoss_G: 0.3161\n",
      "[40/150][300/539]\tLoss_D: 0.2962\tLoss_G: 0.2708\n",
      "[40/150][350/539]\tLoss_D: 0.2065\tLoss_G: 0.5551\n",
      "[40/150][400/539]\tLoss_D: 0.2160\tLoss_G: 0.2477\n",
      "[40/150][450/539]\tLoss_D: 0.3159\tLoss_G: 0.2770\n",
      "[40/150][500/539]\tLoss_D: 0.2213\tLoss_G: 0.3086\n",
      "[41/150][0/539]\tLoss_D: 0.2061\tLoss_G: 0.3183\n",
      "[41/150][50/539]\tLoss_D: 0.2465\tLoss_G: 0.2282\n",
      "[41/150][100/539]\tLoss_D: 0.1160\tLoss_G: 0.1911\n",
      "[41/150][150/539]\tLoss_D: 0.2838\tLoss_G: 0.3825\n",
      "[41/150][200/539]\tLoss_D: 0.2467\tLoss_G: 0.3516\n",
      "[41/150][250/539]\tLoss_D: 0.2330\tLoss_G: 0.2683\n",
      "[41/150][300/539]\tLoss_D: 0.1980\tLoss_G: 0.3045\n",
      "[41/150][350/539]\tLoss_D: 0.2615\tLoss_G: 0.2873\n",
      "[41/150][400/539]\tLoss_D: 0.2367\tLoss_G: 0.2727\n",
      "[41/150][450/539]\tLoss_D: 0.2742\tLoss_G: 0.2389\n",
      "[41/150][500/539]\tLoss_D: 0.2582\tLoss_G: 0.2565\n",
      "[42/150][0/539]\tLoss_D: 0.2404\tLoss_G: 0.1815\n",
      "[42/150][50/539]\tLoss_D: 0.2610\tLoss_G: 0.2441\n",
      "[42/150][100/539]\tLoss_D: 0.2626\tLoss_G: 0.4016\n",
      "[42/150][150/539]\tLoss_D: 0.2989\tLoss_G: 0.2517\n",
      "[42/150][200/539]\tLoss_D: 0.2307\tLoss_G: 0.1515\n",
      "[42/150][250/539]\tLoss_D: 0.2947\tLoss_G: 0.2006\n",
      "[42/150][300/539]\tLoss_D: 0.2477\tLoss_G: 0.2452\n",
      "[42/150][350/539]\tLoss_D: 0.2384\tLoss_G: 0.2973\n",
      "[42/150][400/539]\tLoss_D: 0.2761\tLoss_G: 0.2612\n",
      "[42/150][450/539]\tLoss_D: 0.1402\tLoss_G: 0.1870\n",
      "[42/150][500/539]\tLoss_D: 0.2466\tLoss_G: 0.2619\n",
      "[43/150][0/539]\tLoss_D: 0.2427\tLoss_G: 0.2866\n",
      "[43/150][50/539]\tLoss_D: 0.2678\tLoss_G: 0.3008\n",
      "[43/150][100/539]\tLoss_D: 0.3346\tLoss_G: 0.4056\n",
      "[43/150][150/539]\tLoss_D: 0.3181\tLoss_G: 0.2275\n",
      "[43/150][200/539]\tLoss_D: 0.2437\tLoss_G: 0.2361\n",
      "[43/150][250/539]\tLoss_D: 0.2478\tLoss_G: 0.2861\n",
      "[43/150][300/539]\tLoss_D: 0.2958\tLoss_G: 0.2258\n",
      "[43/150][350/539]\tLoss_D: 0.1626\tLoss_G: 0.3203\n",
      "[43/150][400/539]\tLoss_D: 0.2741\tLoss_G: 0.2404\n",
      "[43/150][450/539]\tLoss_D: 0.2287\tLoss_G: 0.2418\n",
      "[43/150][500/539]\tLoss_D: 0.3201\tLoss_G: 0.2895\n",
      "[44/150][0/539]\tLoss_D: 0.2745\tLoss_G: 0.3355\n",
      "[44/150][50/539]\tLoss_D: 0.2714\tLoss_G: 0.3308\n",
      "[44/150][100/539]\tLoss_D: 0.2931\tLoss_G: 0.1742\n",
      "[44/150][150/539]\tLoss_D: 0.2416\tLoss_G: 0.2472\n",
      "[44/150][200/539]\tLoss_D: 0.2701\tLoss_G: 0.2807\n",
      "[44/150][250/539]\tLoss_D: 0.2457\tLoss_G: 0.2857\n",
      "[44/150][300/539]\tLoss_D: 0.2594\tLoss_G: 0.2784\n",
      "[44/150][350/539]\tLoss_D: 0.2739\tLoss_G: 0.3370\n",
      "[44/150][400/539]\tLoss_D: 0.1291\tLoss_G: 0.3224\n",
      "[44/150][450/539]\tLoss_D: 0.3381\tLoss_G: 0.1346\n",
      "[44/150][500/539]\tLoss_D: 0.2056\tLoss_G: 0.3967\n",
      "[45/150][0/539]\tLoss_D: 0.3881\tLoss_G: 0.3021\n",
      "[45/150][50/539]\tLoss_D: 0.2244\tLoss_G: 0.2535\n",
      "[45/150][100/539]\tLoss_D: 0.2456\tLoss_G: 0.1959\n",
      "[45/150][150/539]\tLoss_D: 0.3289\tLoss_G: 0.3039\n",
      "[45/150][200/539]\tLoss_D: 0.2554\tLoss_G: 0.2941\n",
      "[45/150][250/539]\tLoss_D: 0.2686\tLoss_G: 0.2218\n",
      "[45/150][300/539]\tLoss_D: 0.2466\tLoss_G: 0.2461\n",
      "[45/150][350/539]\tLoss_D: 0.2729\tLoss_G: 0.1394\n",
      "[45/150][400/539]\tLoss_D: 0.2375\tLoss_G: 0.2846\n",
      "[45/150][450/539]\tLoss_D: 0.2428\tLoss_G: 0.3057\n",
      "[45/150][500/539]\tLoss_D: 0.2315\tLoss_G: 0.4430\n",
      "[46/150][0/539]\tLoss_D: 0.3058\tLoss_G: 0.1567\n",
      "[46/150][50/539]\tLoss_D: 0.2199\tLoss_G: 0.2978\n",
      "[46/150][100/539]\tLoss_D: 0.2237\tLoss_G: 0.2968\n",
      "[46/150][150/539]\tLoss_D: 0.2211\tLoss_G: 0.2771\n",
      "[46/150][200/539]\tLoss_D: 0.2267\tLoss_G: 0.3119\n",
      "[46/150][250/539]\tLoss_D: 0.2725\tLoss_G: 0.2861\n",
      "[46/150][300/539]\tLoss_D: 0.3488\tLoss_G: 0.1980\n",
      "[46/150][350/539]\tLoss_D: 0.2489\tLoss_G: 0.2597\n",
      "[46/150][400/539]\tLoss_D: 0.2573\tLoss_G: 0.1917\n",
      "[46/150][450/539]\tLoss_D: 0.2411\tLoss_G: 0.2271\n",
      "[46/150][500/539]\tLoss_D: 0.2613\tLoss_G: 0.2259\n",
      "[47/150][0/539]\tLoss_D: 0.2386\tLoss_G: 0.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/150][50/539]\tLoss_D: 0.2127\tLoss_G: 0.2599\n",
      "[47/150][100/539]\tLoss_D: 0.2482\tLoss_G: 0.2821\n",
      "[47/150][150/539]\tLoss_D: 0.2179\tLoss_G: 0.2913\n",
      "[47/150][200/539]\tLoss_D: 0.2924\tLoss_G: 0.2531\n",
      "[47/150][250/539]\tLoss_D: 0.2067\tLoss_G: 0.2487\n",
      "[47/150][300/539]\tLoss_D: 0.2331\tLoss_G: 0.2761\n",
      "[47/150][350/539]\tLoss_D: 0.2970\tLoss_G: 0.2301\n",
      "[47/150][400/539]\tLoss_D: 0.2578\tLoss_G: 0.1961\n",
      "[47/150][450/539]\tLoss_D: 0.2253\tLoss_G: 0.2054\n",
      "[47/150][500/539]\tLoss_D: 0.2559\tLoss_G: 0.1745\n",
      "[48/150][0/539]\tLoss_D: 0.2308\tLoss_G: 0.2690\n",
      "[48/150][50/539]\tLoss_D: 0.2285\tLoss_G: 0.3724\n",
      "[48/150][100/539]\tLoss_D: 0.2453\tLoss_G: 0.2799\n",
      "[48/150][150/539]\tLoss_D: 0.2409\tLoss_G: 0.2591\n",
      "[48/150][200/539]\tLoss_D: 0.1959\tLoss_G: 0.4223\n",
      "[48/150][250/539]\tLoss_D: 0.2436\tLoss_G: 0.2333\n",
      "[48/150][300/539]\tLoss_D: 0.2227\tLoss_G: 0.3176\n",
      "[48/150][350/539]\tLoss_D: 0.3291\tLoss_G: 0.3416\n",
      "[48/150][400/539]\tLoss_D: 0.2778\tLoss_G: 0.2407\n",
      "[48/150][450/539]\tLoss_D: 0.2509\tLoss_G: 0.2859\n",
      "[48/150][500/539]\tLoss_D: 0.3454\tLoss_G: 0.1411\n",
      "[49/150][0/539]\tLoss_D: 0.2099\tLoss_G: 0.1988\n",
      "[49/150][50/539]\tLoss_D: 0.2300\tLoss_G: 0.2243\n",
      "[49/150][100/539]\tLoss_D: 0.2400\tLoss_G: 0.1425\n",
      "[49/150][150/539]\tLoss_D: 0.3536\tLoss_G: 0.2613\n",
      "[49/150][200/539]\tLoss_D: 0.2031\tLoss_G: 0.2345\n",
      "[49/150][250/539]\tLoss_D: 0.2413\tLoss_G: 0.2844\n",
      "[49/150][300/539]\tLoss_D: 0.2928\tLoss_G: 0.1815\n",
      "[49/150][350/539]\tLoss_D: 0.2572\tLoss_G: 0.2595\n",
      "[49/150][400/539]\tLoss_D: 0.2133\tLoss_G: 0.2818\n",
      "[49/150][450/539]\tLoss_D: 0.2388\tLoss_G: 0.2648\n",
      "[49/150][500/539]\tLoss_D: 0.2960\tLoss_G: 0.2242\n",
      "[50/150][0/539]\tLoss_D: 0.1849\tLoss_G: 0.2264\n",
      "[50/150][50/539]\tLoss_D: 0.2284\tLoss_G: 0.3173\n",
      "[50/150][100/539]\tLoss_D: 0.2518\tLoss_G: 0.2273\n",
      "[50/150][150/539]\tLoss_D: 0.2363\tLoss_G: 0.1384\n",
      "[50/150][200/539]\tLoss_D: 0.1518\tLoss_G: 0.3222\n",
      "[50/150][250/539]\tLoss_D: 0.3212\tLoss_G: 0.1991\n",
      "[50/150][300/539]\tLoss_D: 0.2176\tLoss_G: 0.3004\n",
      "[50/150][350/539]\tLoss_D: 0.2254\tLoss_G: 0.3803\n",
      "[50/150][400/539]\tLoss_D: 0.3377\tLoss_G: 0.3820\n",
      "[50/150][450/539]\tLoss_D: 0.2586\tLoss_G: 0.2887\n",
      "[50/150][500/539]\tLoss_D: 0.2583\tLoss_G: 0.3154\n",
      "[51/150][0/539]\tLoss_D: 0.3003\tLoss_G: 0.3484\n",
      "[51/150][50/539]\tLoss_D: 0.1226\tLoss_G: 0.5182\n",
      "[51/150][100/539]\tLoss_D: 0.1998\tLoss_G: 0.2659\n",
      "[51/150][150/539]\tLoss_D: 0.2328\tLoss_G: 0.3733\n",
      "[51/150][200/539]\tLoss_D: 0.2185\tLoss_G: 0.2588\n",
      "[51/150][250/539]\tLoss_D: 0.2631\tLoss_G: 0.2869\n",
      "[51/150][300/539]\tLoss_D: 0.2395\tLoss_G: 0.3961\n",
      "[51/150][350/539]\tLoss_D: 0.2397\tLoss_G: 0.3233\n",
      "[51/150][400/539]\tLoss_D: 0.2471\tLoss_G: 0.1503\n",
      "[51/150][450/539]\tLoss_D: 0.2228\tLoss_G: 0.2567\n",
      "[51/150][500/539]\tLoss_D: 0.3476\tLoss_G: 0.2848\n",
      "[52/150][0/539]\tLoss_D: 0.2813\tLoss_G: 0.5089\n",
      "[52/150][50/539]\tLoss_D: 0.2260\tLoss_G: 0.3297\n",
      "[52/150][100/539]\tLoss_D: 0.2360\tLoss_G: 0.2610\n",
      "[52/150][150/539]\tLoss_D: 0.2449\tLoss_G: 0.2461\n",
      "[52/150][200/539]\tLoss_D: 0.2739\tLoss_G: 0.2393\n",
      "[52/150][250/539]\tLoss_D: 0.2075\tLoss_G: 0.3406\n",
      "[52/150][300/539]\tLoss_D: 0.2433\tLoss_G: 0.2671\n",
      "[52/150][350/539]\tLoss_D: 0.2117\tLoss_G: 0.3765\n",
      "[52/150][400/539]\tLoss_D: 0.2810\tLoss_G: 0.4813\n",
      "[52/150][450/539]\tLoss_D: 0.2705\tLoss_G: 0.2778\n",
      "[52/150][500/539]\tLoss_D: 0.2736\tLoss_G: 0.2009\n",
      "[53/150][0/539]\tLoss_D: 0.2341\tLoss_G: 0.2760\n",
      "[53/150][50/539]\tLoss_D: 0.1524\tLoss_G: 0.3159\n",
      "[53/150][100/539]\tLoss_D: 0.2878\tLoss_G: 0.2336\n",
      "[53/150][150/539]\tLoss_D: 0.1859\tLoss_G: 0.2343\n",
      "[53/150][200/539]\tLoss_D: 0.2315\tLoss_G: 0.3158\n",
      "[53/150][250/539]\tLoss_D: 0.0871\tLoss_G: 0.2885\n",
      "[53/150][300/539]\tLoss_D: 0.2451\tLoss_G: 0.2643\n",
      "[53/150][350/539]\tLoss_D: 0.1716\tLoss_G: 0.3591\n",
      "[53/150][400/539]\tLoss_D: 0.2608\tLoss_G: 0.5972\n",
      "[53/150][450/539]\tLoss_D: 0.1228\tLoss_G: 0.1777\n",
      "[53/150][500/539]\tLoss_D: 0.2117\tLoss_G: 0.3083\n",
      "[54/150][0/539]\tLoss_D: 0.1467\tLoss_G: 0.2230\n",
      "[54/150][50/539]\tLoss_D: 0.2449\tLoss_G: 0.2633\n",
      "[54/150][100/539]\tLoss_D: 0.1966\tLoss_G: 0.3952\n",
      "[54/150][150/539]\tLoss_D: 0.2009\tLoss_G: 0.3950\n",
      "[54/150][200/539]\tLoss_D: 0.1784\tLoss_G: 0.4649\n",
      "[54/150][250/539]\tLoss_D: 0.3294\tLoss_G: 0.2556\n",
      "[54/150][300/539]\tLoss_D: 0.1359\tLoss_G: 0.4456\n",
      "[54/150][350/539]\tLoss_D: 0.2209\tLoss_G: 0.3322\n",
      "[54/150][400/539]\tLoss_D: 0.2064\tLoss_G: 0.4111\n",
      "[54/150][450/539]\tLoss_D: 0.2376\tLoss_G: 0.5179\n",
      "[54/150][500/539]\tLoss_D: 0.1693\tLoss_G: 0.3331\n",
      "[55/150][0/539]\tLoss_D: 0.1880\tLoss_G: 0.4198\n",
      "[55/150][50/539]\tLoss_D: 0.2628\tLoss_G: 0.3612\n",
      "[55/150][100/539]\tLoss_D: 0.1325\tLoss_G: 0.4220\n",
      "[55/150][150/539]\tLoss_D: 0.0844\tLoss_G: 0.4071\n",
      "[55/150][200/539]\tLoss_D: 0.1171\tLoss_G: 0.3295\n",
      "[55/150][250/539]\tLoss_D: 0.1963\tLoss_G: 0.3571\n",
      "[55/150][300/539]\tLoss_D: 0.2025\tLoss_G: 0.1934\n",
      "[55/150][350/539]\tLoss_D: 0.1636\tLoss_G: 0.8757\n",
      "[55/150][400/539]\tLoss_D: 0.1724\tLoss_G: 0.5689\n",
      "[55/150][450/539]\tLoss_D: 0.1085\tLoss_G: 0.6596\n",
      "[55/150][500/539]\tLoss_D: 0.1208\tLoss_G: 0.2557\n",
      "[56/150][0/539]\tLoss_D: 0.1255\tLoss_G: 0.4691\n",
      "[56/150][50/539]\tLoss_D: 0.1580\tLoss_G: 0.1612\n",
      "[56/150][100/539]\tLoss_D: 0.0780\tLoss_G: 0.8758\n",
      "[56/150][150/539]\tLoss_D: 0.4090\tLoss_G: 0.8561\n",
      "[56/150][200/539]\tLoss_D: 0.0272\tLoss_G: 0.9222\n",
      "[56/150][250/539]\tLoss_D: 0.1429\tLoss_G: 0.4875\n",
      "[56/150][300/539]\tLoss_D: 0.0424\tLoss_G: 0.6061\n",
      "[56/150][350/539]\tLoss_D: 0.1852\tLoss_G: 0.1926\n",
      "[56/150][400/539]\tLoss_D: 0.1308\tLoss_G: 0.4234\n",
      "[56/150][450/539]\tLoss_D: 0.2713\tLoss_G: 0.4634\n",
      "[56/150][500/539]\tLoss_D: 0.2163\tLoss_G: 0.8051\n",
      "[57/150][0/539]\tLoss_D: 0.1244\tLoss_G: 0.3048\n",
      "[57/150][50/539]\tLoss_D: 0.2690\tLoss_G: 0.3003\n",
      "[57/150][100/539]\tLoss_D: 0.1942\tLoss_G: 0.4499\n",
      "[57/150][150/539]\tLoss_D: 0.2833\tLoss_G: 0.3354\n",
      "[57/150][200/539]\tLoss_D: 0.3365\tLoss_G: 0.4551\n",
      "[57/150][250/539]\tLoss_D: 0.1085\tLoss_G: 0.3604\n",
      "[57/150][300/539]\tLoss_D: 0.3294\tLoss_G: 0.4097\n",
      "[57/150][350/539]\tLoss_D: 0.1503\tLoss_G: 0.6193\n",
      "[57/150][400/539]\tLoss_D: 0.2601\tLoss_G: 0.5181\n",
      "[57/150][450/539]\tLoss_D: 0.3900\tLoss_G: 0.2742\n",
      "[57/150][500/539]\tLoss_D: 0.2972\tLoss_G: 0.4586\n",
      "[58/150][0/539]\tLoss_D: 0.2143\tLoss_G: 0.0506\n",
      "[58/150][50/539]\tLoss_D: 0.0817\tLoss_G: 0.2378\n",
      "[58/150][100/539]\tLoss_D: 0.1280\tLoss_G: 0.5642\n",
      "[58/150][150/539]\tLoss_D: 0.3430\tLoss_G: 0.4245\n",
      "[58/150][200/539]\tLoss_D: 0.0757\tLoss_G: 0.5834\n",
      "[58/150][250/539]\tLoss_D: 0.1107\tLoss_G: 0.4792\n",
      "[58/150][300/539]\tLoss_D: 0.0652\tLoss_G: 0.4239\n",
      "[58/150][350/539]\tLoss_D: 0.0258\tLoss_G: 0.0551\n",
      "[58/150][400/539]\tLoss_D: 0.3387\tLoss_G: 0.4085\n",
      "[58/150][450/539]\tLoss_D: 0.3284\tLoss_G: 0.3652\n",
      "[58/150][500/539]\tLoss_D: 0.1911\tLoss_G: 0.1736\n",
      "[59/150][0/539]\tLoss_D: 0.0500\tLoss_G: 0.4556\n",
      "[59/150][50/539]\tLoss_D: 0.1607\tLoss_G: 0.6114\n",
      "[59/150][100/539]\tLoss_D: 0.1664\tLoss_G: 0.3933\n",
      "[59/150][150/539]\tLoss_D: 0.0106\tLoss_G: 0.6992\n",
      "[59/150][200/539]\tLoss_D: 0.2059\tLoss_G: 0.4562\n",
      "[59/150][250/539]\tLoss_D: 0.0600\tLoss_G: 1.1801\n",
      "[59/150][300/539]\tLoss_D: 0.0534\tLoss_G: 0.3335\n",
      "[59/150][350/539]\tLoss_D: 0.1139\tLoss_G: 0.5789\n",
      "[59/150][400/539]\tLoss_D: 0.0874\tLoss_G: 0.6076\n",
      "[59/150][450/539]\tLoss_D: 0.2317\tLoss_G: 0.4688\n",
      "[59/150][500/539]\tLoss_D: 0.2532\tLoss_G: 0.5948\n",
      "[60/150][0/539]\tLoss_D: 0.3465\tLoss_G: 0.1056\n",
      "[60/150][50/539]\tLoss_D: 0.3335\tLoss_G: 0.5824\n",
      "[60/150][100/539]\tLoss_D: 0.1368\tLoss_G: 0.5622\n",
      "[60/150][150/539]\tLoss_D: 0.2815\tLoss_G: 0.2570\n",
      "[60/150][200/539]\tLoss_D: 0.1893\tLoss_G: 0.4274\n",
      "[60/150][250/539]\tLoss_D: 0.1337\tLoss_G: 0.3475\n",
      "[60/150][300/539]\tLoss_D: 0.0675\tLoss_G: 0.2742\n",
      "[60/150][350/539]\tLoss_D: 0.2811\tLoss_G: 0.7900\n",
      "[60/150][400/539]\tLoss_D: 0.3866\tLoss_G: 0.8144\n",
      "[60/150][450/539]\tLoss_D: 0.1791\tLoss_G: 0.0508\n",
      "[60/150][500/539]\tLoss_D: 0.0611\tLoss_G: 0.3152\n",
      "[61/150][0/539]\tLoss_D: 0.1683\tLoss_G: 0.4234\n",
      "[61/150][50/539]\tLoss_D: 0.1111\tLoss_G: 0.3822\n",
      "[61/150][100/539]\tLoss_D: 0.2177\tLoss_G: 0.4607\n",
      "[61/150][150/539]\tLoss_D: 0.0395\tLoss_G: 0.5149\n",
      "[61/150][200/539]\tLoss_D: 0.0622\tLoss_G: 0.2776\n",
      "[61/150][250/539]\tLoss_D: 0.1153\tLoss_G: 0.3902\n",
      "[61/150][300/539]\tLoss_D: 0.1884\tLoss_G: 0.5312\n",
      "[61/150][350/539]\tLoss_D: 0.0345\tLoss_G: 0.5823\n",
      "[61/150][400/539]\tLoss_D: 0.0835\tLoss_G: 1.5293\n",
      "[61/150][450/539]\tLoss_D: 0.1338\tLoss_G: 0.3207\n",
      "[61/150][500/539]\tLoss_D: 0.1477\tLoss_G: 0.4840\n",
      "[62/150][0/539]\tLoss_D: 0.3405\tLoss_G: 0.7572\n",
      "[62/150][50/539]\tLoss_D: 0.1162\tLoss_G: 0.6785\n",
      "[62/150][100/539]\tLoss_D: 0.1715\tLoss_G: 0.5269\n",
      "[62/150][150/539]\tLoss_D: 0.2209\tLoss_G: 0.3731\n",
      "[62/150][200/539]\tLoss_D: 0.1849\tLoss_G: 0.2035\n",
      "[62/150][250/539]\tLoss_D: 0.2004\tLoss_G: 0.4087\n",
      "[62/150][300/539]\tLoss_D: 0.3206\tLoss_G: 0.4536\n",
      "[62/150][350/539]\tLoss_D: 0.1201\tLoss_G: 0.3016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62/150][400/539]\tLoss_D: 0.1430\tLoss_G: 0.5573\n",
      "[62/150][450/539]\tLoss_D: 0.1235\tLoss_G: 0.6461\n",
      "[62/150][500/539]\tLoss_D: 0.0782\tLoss_G: 0.3921\n",
      "[63/150][0/539]\tLoss_D: 0.0950\tLoss_G: 0.3613\n",
      "[63/150][50/539]\tLoss_D: 0.1847\tLoss_G: 0.4166\n",
      "[63/150][100/539]\tLoss_D: 0.1865\tLoss_G: 0.4760\n",
      "[63/150][150/539]\tLoss_D: 0.1055\tLoss_G: 0.6341\n",
      "[63/150][200/539]\tLoss_D: 0.1930\tLoss_G: 0.4738\n",
      "[63/150][250/539]\tLoss_D: 0.0854\tLoss_G: 0.6335\n",
      "[63/150][300/539]\tLoss_D: 0.2924\tLoss_G: 0.5859\n",
      "[63/150][350/539]\tLoss_D: 0.1674\tLoss_G: 0.8553\n",
      "[63/150][400/539]\tLoss_D: 0.0902\tLoss_G: 0.5650\n",
      "[63/150][450/539]\tLoss_D: 0.2567\tLoss_G: 0.4846\n",
      "[63/150][500/539]\tLoss_D: 0.2006\tLoss_G: 0.4832\n",
      "[64/150][0/539]\tLoss_D: 0.1399\tLoss_G: 0.6895\n",
      "[64/150][50/539]\tLoss_D: 0.2535\tLoss_G: 0.2475\n",
      "[64/150][100/539]\tLoss_D: 0.0866\tLoss_G: 0.5177\n",
      "[64/150][150/539]\tLoss_D: 0.1540\tLoss_G: 0.2805\n",
      "[64/150][200/539]\tLoss_D: 0.1427\tLoss_G: 0.4816\n",
      "[64/150][250/539]\tLoss_D: 0.0574\tLoss_G: 0.3694\n",
      "[64/150][300/539]\tLoss_D: 0.2096\tLoss_G: 0.3076\n",
      "[64/150][350/539]\tLoss_D: 0.0854\tLoss_G: 0.7661\n",
      "[64/150][400/539]\tLoss_D: 0.1310\tLoss_G: 0.6781\n",
      "[64/150][450/539]\tLoss_D: 0.3401\tLoss_G: 0.6443\n",
      "[64/150][500/539]\tLoss_D: 0.0759\tLoss_G: 0.5816\n",
      "[65/150][0/539]\tLoss_D: 0.6402\tLoss_G: 0.2189\n",
      "[65/150][50/539]\tLoss_D: 0.0730\tLoss_G: 1.6511\n",
      "[65/150][100/539]\tLoss_D: 0.1675\tLoss_G: 0.5532\n",
      "[65/150][150/539]\tLoss_D: 0.1232\tLoss_G: 0.9862\n",
      "[65/150][200/539]\tLoss_D: 0.2589\tLoss_G: 0.6753\n",
      "[65/150][250/539]\tLoss_D: 0.1012\tLoss_G: 0.5047\n",
      "[65/150][300/539]\tLoss_D: 0.0278\tLoss_G: 0.4454\n",
      "[65/150][350/539]\tLoss_D: 0.1536\tLoss_G: 0.1634\n",
      "[65/150][400/539]\tLoss_D: 0.1681\tLoss_G: 0.2191\n",
      "[65/150][450/539]\tLoss_D: 0.0498\tLoss_G: 0.3380\n",
      "[65/150][500/539]\tLoss_D: 0.0592\tLoss_G: 0.6007\n",
      "[66/150][0/539]\tLoss_D: 0.5106\tLoss_G: 0.3855\n",
      "[66/150][50/539]\tLoss_D: 0.1406\tLoss_G: 0.8371\n",
      "[66/150][100/539]\tLoss_D: 0.0581\tLoss_G: 0.7121\n",
      "[66/150][150/539]\tLoss_D: 0.2527\tLoss_G: 0.7324\n",
      "[66/150][200/539]\tLoss_D: 0.2073\tLoss_G: 0.5984\n",
      "[66/150][250/539]\tLoss_D: 0.2055\tLoss_G: 0.7406\n",
      "[66/150][300/539]\tLoss_D: 0.1613\tLoss_G: 0.5812\n",
      "[66/150][350/539]\tLoss_D: 0.1999\tLoss_G: 0.2655\n",
      "[66/150][400/539]\tLoss_D: 0.1022\tLoss_G: 0.6443\n",
      "[66/150][450/539]\tLoss_D: 0.2514\tLoss_G: 0.0896\n",
      "[66/150][500/539]\tLoss_D: 0.1349\tLoss_G: 0.4876\n",
      "[67/150][0/539]\tLoss_D: 0.2961\tLoss_G: 0.0978\n",
      "[67/150][50/539]\tLoss_D: 0.0524\tLoss_G: 0.2766\n",
      "[67/150][100/539]\tLoss_D: 0.0738\tLoss_G: 0.3969\n",
      "[67/150][150/539]\tLoss_D: 0.0825\tLoss_G: 0.5212\n",
      "[67/150][200/539]\tLoss_D: 0.2570\tLoss_G: 0.3722\n",
      "[67/150][250/539]\tLoss_D: 0.1422\tLoss_G: 0.7369\n",
      "[67/150][300/539]\tLoss_D: 0.1898\tLoss_G: 0.7349\n",
      "[67/150][350/539]\tLoss_D: 0.2024\tLoss_G: 0.4392\n",
      "[67/150][400/539]\tLoss_D: 0.0623\tLoss_G: 0.2821\n",
      "[67/150][450/539]\tLoss_D: 0.1172\tLoss_G: 0.5955\n",
      "[67/150][500/539]\tLoss_D: 0.0473\tLoss_G: 0.8172\n",
      "[68/150][0/539]\tLoss_D: 0.1113\tLoss_G: 0.3813\n",
      "[68/150][50/539]\tLoss_D: 0.0305\tLoss_G: 0.4254\n",
      "[68/150][100/539]\tLoss_D: 0.0130\tLoss_G: 1.2010\n",
      "[68/150][150/539]\tLoss_D: 0.0560\tLoss_G: 0.4314\n",
      "[68/150][200/539]\tLoss_D: 0.2743\tLoss_G: 0.3808\n",
      "[68/150][250/539]\tLoss_D: 0.1687\tLoss_G: 0.7297\n",
      "[68/150][300/539]\tLoss_D: 0.1169\tLoss_G: 0.5645\n",
      "[68/150][350/539]\tLoss_D: 0.1981\tLoss_G: 0.5555\n",
      "[68/150][400/539]\tLoss_D: 0.0820\tLoss_G: 0.4397\n",
      "[68/150][450/539]\tLoss_D: 0.0411\tLoss_G: 0.5979\n",
      "[68/150][500/539]\tLoss_D: 0.0466\tLoss_G: 0.3721\n",
      "[69/150][0/539]\tLoss_D: 0.1453\tLoss_G: 0.2645\n",
      "[69/150][50/539]\tLoss_D: 0.0882\tLoss_G: 0.2398\n",
      "[69/150][100/539]\tLoss_D: 0.0487\tLoss_G: 0.5416\n",
      "[69/150][150/539]\tLoss_D: 0.2068\tLoss_G: 0.6728\n",
      "[69/150][200/539]\tLoss_D: 0.1193\tLoss_G: 0.3553\n",
      "[69/150][250/539]\tLoss_D: 0.0739\tLoss_G: 0.5753\n",
      "[69/150][300/539]\tLoss_D: 0.3895\tLoss_G: 0.6978\n",
      "[69/150][350/539]\tLoss_D: 0.2277\tLoss_G: 0.3833\n",
      "[69/150][400/539]\tLoss_D: 0.0991\tLoss_G: 0.7069\n",
      "[69/150][450/539]\tLoss_D: 0.1038\tLoss_G: 0.3082\n",
      "[69/150][500/539]\tLoss_D: 0.0940\tLoss_G: 0.4240\n",
      "[70/150][0/539]\tLoss_D: 0.2407\tLoss_G: 0.2572\n",
      "[70/150][50/539]\tLoss_D: 0.0983\tLoss_G: 0.4735\n",
      "[70/150][100/539]\tLoss_D: 0.1217\tLoss_G: 0.6483\n",
      "[70/150][150/539]\tLoss_D: 0.1927\tLoss_G: 0.4810\n",
      "[70/150][200/539]\tLoss_D: 0.0896\tLoss_G: 0.4965\n",
      "[70/150][250/539]\tLoss_D: 0.0364\tLoss_G: 0.6936\n",
      "[70/150][300/539]\tLoss_D: 0.0799\tLoss_G: 0.6823\n",
      "[70/150][350/539]\tLoss_D: 0.0703\tLoss_G: 0.5805\n",
      "[70/150][400/539]\tLoss_D: 0.0417\tLoss_G: 0.7584\n",
      "[70/150][450/539]\tLoss_D: 0.3030\tLoss_G: 0.2554\n",
      "[70/150][500/539]\tLoss_D: 0.1255\tLoss_G: 0.4620\n",
      "[71/150][0/539]\tLoss_D: 0.0985\tLoss_G: 0.6392\n",
      "[71/150][50/539]\tLoss_D: 0.1088\tLoss_G: 0.2228\n",
      "[71/150][100/539]\tLoss_D: 0.1062\tLoss_G: 1.1550\n",
      "[71/150][150/539]\tLoss_D: 0.0645\tLoss_G: 0.5193\n",
      "[71/150][200/539]\tLoss_D: 0.1754\tLoss_G: 0.3344\n",
      "[71/150][250/539]\tLoss_D: 0.1821\tLoss_G: 0.5111\n",
      "[71/150][300/539]\tLoss_D: 0.1910\tLoss_G: 0.7312\n",
      "[71/150][350/539]\tLoss_D: 0.1600\tLoss_G: 0.6067\n",
      "[71/150][400/539]\tLoss_D: 0.2378\tLoss_G: 0.9379\n",
      "[71/150][450/539]\tLoss_D: 0.1658\tLoss_G: 0.5644\n",
      "[71/150][500/539]\tLoss_D: 0.0756\tLoss_G: 0.2397\n",
      "[72/150][0/539]\tLoss_D: 0.2062\tLoss_G: 0.4836\n",
      "[72/150][50/539]\tLoss_D: 0.1333\tLoss_G: 0.4822\n",
      "[72/150][100/539]\tLoss_D: 0.2189\tLoss_G: 0.5870\n",
      "[72/150][150/539]\tLoss_D: 0.1637\tLoss_G: 0.3008\n",
      "[72/150][200/539]\tLoss_D: 0.0261\tLoss_G: 0.7157\n",
      "[72/150][250/539]\tLoss_D: 0.0934\tLoss_G: 0.4484\n",
      "[72/150][300/539]\tLoss_D: 0.0696\tLoss_G: 0.4884\n",
      "[72/150][350/539]\tLoss_D: 0.0882\tLoss_G: 0.5171\n",
      "[72/150][400/539]\tLoss_D: 0.3295\tLoss_G: 0.8438\n",
      "[72/150][450/539]\tLoss_D: 0.0246\tLoss_G: 0.7076\n",
      "[72/150][500/539]\tLoss_D: 0.0898\tLoss_G: 0.2282\n",
      "[73/150][0/539]\tLoss_D: 0.3055\tLoss_G: 0.4409\n",
      "[73/150][50/539]\tLoss_D: 0.1375\tLoss_G: 0.1068\n",
      "[73/150][100/539]\tLoss_D: 0.0369\tLoss_G: 0.7070\n",
      "[73/150][150/539]\tLoss_D: 0.4469\tLoss_G: 0.4330\n",
      "[73/150][200/539]\tLoss_D: 0.1690\tLoss_G: 0.4719\n",
      "[73/150][250/539]\tLoss_D: 0.0700\tLoss_G: 0.7374\n",
      "[73/150][300/539]\tLoss_D: 0.2960\tLoss_G: 0.6306\n",
      "[73/150][350/539]\tLoss_D: 0.1645\tLoss_G: 0.5361\n",
      "[73/150][400/539]\tLoss_D: 0.3549\tLoss_G: 0.2278\n",
      "[73/150][450/539]\tLoss_D: 0.0575\tLoss_G: 0.5239\n",
      "[73/150][500/539]\tLoss_D: 0.2958\tLoss_G: 0.3307\n",
      "[74/150][0/539]\tLoss_D: 0.2219\tLoss_G: 0.4052\n",
      "[74/150][50/539]\tLoss_D: 0.1019\tLoss_G: 0.4227\n",
      "[74/150][100/539]\tLoss_D: 0.1160\tLoss_G: 0.3776\n",
      "[74/150][150/539]\tLoss_D: 0.1866\tLoss_G: 0.1842\n",
      "[74/150][200/539]\tLoss_D: 0.0318\tLoss_G: 0.2715\n",
      "[74/150][250/539]\tLoss_D: 0.0990\tLoss_G: 0.3713\n",
      "[74/150][300/539]\tLoss_D: 0.4122\tLoss_G: 0.2624\n",
      "[74/150][350/539]\tLoss_D: 0.1161\tLoss_G: 0.3708\n",
      "[74/150][400/539]\tLoss_D: 0.0623\tLoss_G: 0.6119\n",
      "[74/150][450/539]\tLoss_D: 0.2192\tLoss_G: 0.2828\n",
      "[74/150][500/539]\tLoss_D: 0.1827\tLoss_G: 0.5160\n",
      "[75/150][0/539]\tLoss_D: 0.0545\tLoss_G: 0.5017\n",
      "[75/150][50/539]\tLoss_D: 0.2808\tLoss_G: 0.6324\n",
      "[75/150][100/539]\tLoss_D: 0.0288\tLoss_G: 1.1911\n",
      "[75/150][150/539]\tLoss_D: 0.1223\tLoss_G: 0.9210\n",
      "[75/150][200/539]\tLoss_D: 0.1380\tLoss_G: 0.5756\n",
      "[75/150][250/539]\tLoss_D: 0.0341\tLoss_G: 0.7891\n",
      "[75/150][300/539]\tLoss_D: 0.0751\tLoss_G: 0.6780\n",
      "[75/150][350/539]\tLoss_D: 0.0333\tLoss_G: 0.5771\n",
      "[75/150][400/539]\tLoss_D: 0.0916\tLoss_G: 0.6784\n",
      "[75/150][450/539]\tLoss_D: 0.1332\tLoss_G: 0.9324\n",
      "[75/150][500/539]\tLoss_D: 0.1136\tLoss_G: 0.7313\n",
      "[76/150][0/539]\tLoss_D: 0.0394\tLoss_G: 0.5887\n",
      "[76/150][50/539]\tLoss_D: 0.1864\tLoss_G: 0.6487\n",
      "[76/150][100/539]\tLoss_D: 0.1131\tLoss_G: 0.3400\n",
      "[76/150][150/539]\tLoss_D: 0.4093\tLoss_G: 0.4430\n",
      "[76/150][200/539]\tLoss_D: 0.2129\tLoss_G: 0.3581\n",
      "[76/150][250/539]\tLoss_D: 0.0861\tLoss_G: 0.6633\n",
      "[76/150][300/539]\tLoss_D: 0.1210\tLoss_G: 0.5906\n",
      "[76/150][350/539]\tLoss_D: 0.4289\tLoss_G: 0.4450\n",
      "[76/150][400/539]\tLoss_D: 0.1632\tLoss_G: 0.6590\n",
      "[76/150][450/539]\tLoss_D: 0.0677\tLoss_G: 0.5233\n",
      "[76/150][500/539]\tLoss_D: 0.0941\tLoss_G: 0.7258\n",
      "[77/150][0/539]\tLoss_D: 0.1634\tLoss_G: 0.4273\n",
      "[77/150][50/539]\tLoss_D: 0.1895\tLoss_G: 0.6576\n",
      "[77/150][100/539]\tLoss_D: 0.4405\tLoss_G: 0.9056\n",
      "[77/150][150/539]\tLoss_D: 0.0103\tLoss_G: 0.9085\n",
      "[77/150][200/539]\tLoss_D: 0.1071\tLoss_G: 0.3195\n",
      "[77/150][250/539]\tLoss_D: 0.2153\tLoss_G: 0.5454\n",
      "[77/150][300/539]\tLoss_D: 0.1117\tLoss_G: 0.9331\n",
      "[77/150][350/539]\tLoss_D: 0.0737\tLoss_G: 0.3385\n",
      "[77/150][400/539]\tLoss_D: 0.0821\tLoss_G: 0.3993\n",
      "[77/150][450/539]\tLoss_D: 0.0180\tLoss_G: 1.2864\n",
      "[77/150][500/539]\tLoss_D: 0.1475\tLoss_G: 0.6737\n",
      "[78/150][0/539]\tLoss_D: 0.2032\tLoss_G: 0.3930\n",
      "[78/150][50/539]\tLoss_D: 0.1251\tLoss_G: 0.5602\n",
      "[78/150][100/539]\tLoss_D: 0.0441\tLoss_G: 0.5044\n",
      "[78/150][150/539]\tLoss_D: 0.0462\tLoss_G: 0.3146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/150][200/539]\tLoss_D: 0.0932\tLoss_G: 0.4230\n",
      "[78/150][250/539]\tLoss_D: 0.0335\tLoss_G: 0.6837\n",
      "[78/150][300/539]\tLoss_D: 0.1495\tLoss_G: 0.4548\n",
      "[78/150][350/539]\tLoss_D: 0.0699\tLoss_G: 0.5051\n",
      "[78/150][400/539]\tLoss_D: 0.2749\tLoss_G: 0.4447\n",
      "[78/150][450/539]\tLoss_D: 0.3545\tLoss_G: 0.7242\n",
      "[78/150][500/539]\tLoss_D: 0.0272\tLoss_G: 0.5319\n",
      "[79/150][0/539]\tLoss_D: 0.0532\tLoss_G: 0.7339\n",
      "[79/150][50/539]\tLoss_D: 0.1144\tLoss_G: 0.3877\n",
      "[79/150][100/539]\tLoss_D: 0.1259\tLoss_G: 0.4104\n",
      "[79/150][150/539]\tLoss_D: 0.1688\tLoss_G: 0.5692\n",
      "[79/150][200/539]\tLoss_D: 0.0603\tLoss_G: 0.3713\n",
      "[79/150][250/539]\tLoss_D: 0.1260\tLoss_G: 0.3747\n",
      "[79/150][300/539]\tLoss_D: 0.0877\tLoss_G: 0.5653\n",
      "[79/150][350/539]\tLoss_D: 0.1789\tLoss_G: 0.3879\n",
      "[79/150][400/539]\tLoss_D: 0.0595\tLoss_G: 1.2211\n",
      "[79/150][450/539]\tLoss_D: 0.0596\tLoss_G: 0.3637\n",
      "[79/150][500/539]\tLoss_D: 0.0337\tLoss_G: 0.6018\n",
      "[80/150][0/539]\tLoss_D: 0.1925\tLoss_G: 0.5743\n",
      "[80/150][50/539]\tLoss_D: 0.1206\tLoss_G: 0.6601\n",
      "[80/150][100/539]\tLoss_D: 0.0609\tLoss_G: 0.6256\n",
      "[80/150][150/539]\tLoss_D: 0.0553\tLoss_G: 0.5757\n",
      "[80/150][200/539]\tLoss_D: 0.0475\tLoss_G: 0.3005\n",
      "[80/150][250/539]\tLoss_D: 0.1999\tLoss_G: 0.8099\n",
      "[80/150][300/539]\tLoss_D: 0.0462\tLoss_G: 0.7071\n",
      "[80/150][350/539]\tLoss_D: 0.2030\tLoss_G: 0.6320\n",
      "[80/150][400/539]\tLoss_D: 0.0755\tLoss_G: 0.6251\n",
      "[80/150][450/539]\tLoss_D: 0.2016\tLoss_G: 0.4210\n",
      "[80/150][500/539]\tLoss_D: 0.0892\tLoss_G: 0.3643\n",
      "[81/150][0/539]\tLoss_D: 0.3359\tLoss_G: 0.6625\n",
      "[81/150][50/539]\tLoss_D: 0.1058\tLoss_G: 0.5611\n",
      "[81/150][100/539]\tLoss_D: 0.3150\tLoss_G: 0.8092\n",
      "[81/150][150/539]\tLoss_D: 0.1428\tLoss_G: 0.2499\n",
      "[81/150][200/539]\tLoss_D: 0.0636\tLoss_G: 0.5184\n",
      "[81/150][250/539]\tLoss_D: 0.0741\tLoss_G: 0.5260\n",
      "[81/150][300/539]\tLoss_D: 0.0622\tLoss_G: 0.4594\n",
      "[81/150][350/539]\tLoss_D: 0.1165\tLoss_G: 0.5877\n",
      "[81/150][400/539]\tLoss_D: 0.0886\tLoss_G: 0.5154\n",
      "[81/150][450/539]\tLoss_D: 0.1072\tLoss_G: 0.5214\n",
      "[81/150][500/539]\tLoss_D: 0.1206\tLoss_G: 0.4893\n",
      "[82/150][0/539]\tLoss_D: 0.1741\tLoss_G: 0.6098\n",
      "[82/150][50/539]\tLoss_D: 0.0633\tLoss_G: 0.5918\n",
      "[82/150][100/539]\tLoss_D: 0.1849\tLoss_G: 0.5233\n",
      "[82/150][150/539]\tLoss_D: 0.1083\tLoss_G: 0.6392\n",
      "[82/150][200/539]\tLoss_D: 0.0519\tLoss_G: 0.5390\n",
      "[82/150][250/539]\tLoss_D: 0.0908\tLoss_G: 0.6240\n",
      "[82/150][300/539]\tLoss_D: 0.0838\tLoss_G: 0.6663\n",
      "[82/150][350/539]\tLoss_D: 0.0882\tLoss_G: 0.8101\n",
      "[82/150][400/539]\tLoss_D: 0.2357\tLoss_G: 0.1200\n",
      "[82/150][450/539]\tLoss_D: 0.1287\tLoss_G: 0.4322\n",
      "[82/150][500/539]\tLoss_D: 0.3426\tLoss_G: 0.3535\n",
      "[83/150][0/539]\tLoss_D: 0.0568\tLoss_G: 0.4572\n",
      "[83/150][50/539]\tLoss_D: 0.2057\tLoss_G: 0.5740\n",
      "[83/150][100/539]\tLoss_D: 0.0962\tLoss_G: 0.4173\n",
      "[83/150][150/539]\tLoss_D: 0.0984\tLoss_G: 0.3008\n",
      "[83/150][200/539]\tLoss_D: 0.1476\tLoss_G: 0.6642\n",
      "[83/150][250/539]\tLoss_D: 0.2356\tLoss_G: 0.4807\n",
      "[83/150][300/539]\tLoss_D: 0.1730\tLoss_G: 0.5922\n",
      "[83/150][350/539]\tLoss_D: 0.1054\tLoss_G: 0.7878\n",
      "[83/150][400/539]\tLoss_D: 0.0371\tLoss_G: 0.6432\n",
      "[83/150][450/539]\tLoss_D: 0.2083\tLoss_G: 0.4502\n",
      "[83/150][500/539]\tLoss_D: 0.2369\tLoss_G: 0.5602\n",
      "[84/150][0/539]\tLoss_D: 0.0350\tLoss_G: 0.5274\n",
      "[84/150][50/539]\tLoss_D: 0.1053\tLoss_G: 0.3441\n",
      "[84/150][100/539]\tLoss_D: 0.0306\tLoss_G: 0.4075\n",
      "[84/150][150/539]\tLoss_D: 0.1097\tLoss_G: 0.4027\n",
      "[84/150][200/539]\tLoss_D: 0.0505\tLoss_G: 0.4460\n",
      "[84/150][250/539]\tLoss_D: 0.0901\tLoss_G: 0.5232\n",
      "[84/150][300/539]\tLoss_D: 0.1703\tLoss_G: 0.6884\n",
      "[84/150][350/539]\tLoss_D: 0.0924\tLoss_G: 0.4368\n",
      "[84/150][400/539]\tLoss_D: 0.0937\tLoss_G: 0.5835\n",
      "[84/150][450/539]\tLoss_D: 0.1854\tLoss_G: 0.1985\n",
      "[84/150][500/539]\tLoss_D: 0.0469\tLoss_G: 0.5563\n",
      "[85/150][0/539]\tLoss_D: 0.1161\tLoss_G: 0.4773\n",
      "[85/150][50/539]\tLoss_D: 0.1139\tLoss_G: 0.6238\n",
      "[85/150][100/539]\tLoss_D: 0.1645\tLoss_G: 0.2667\n",
      "[85/150][150/539]\tLoss_D: 0.0939\tLoss_G: 0.3068\n",
      "[85/150][200/539]\tLoss_D: 0.4077\tLoss_G: 0.6372\n",
      "[85/150][250/539]\tLoss_D: 0.1990\tLoss_G: 0.2124\n",
      "[85/150][300/539]\tLoss_D: 0.2557\tLoss_G: 0.4990\n",
      "[85/150][350/539]\tLoss_D: 0.0871\tLoss_G: 0.6101\n",
      "[85/150][400/539]\tLoss_D: 0.1576\tLoss_G: 0.4456\n",
      "[85/150][450/539]\tLoss_D: 0.2170\tLoss_G: 0.3983\n",
      "[85/150][500/539]\tLoss_D: 0.0400\tLoss_G: 0.5566\n",
      "[86/150][0/539]\tLoss_D: 0.1554\tLoss_G: 0.4135\n",
      "[86/150][50/539]\tLoss_D: 0.1351\tLoss_G: 0.4541\n",
      "[86/150][100/539]\tLoss_D: 0.0860\tLoss_G: 0.4471\n",
      "[86/150][150/539]\tLoss_D: 0.2105\tLoss_G: 0.2971\n",
      "[86/150][200/539]\tLoss_D: 0.1178\tLoss_G: 0.8866\n",
      "[86/150][250/539]\tLoss_D: 0.1384\tLoss_G: 0.8867\n",
      "[86/150][300/539]\tLoss_D: 0.0660\tLoss_G: 0.2913\n",
      "[86/150][350/539]\tLoss_D: 0.0928\tLoss_G: 0.4172\n",
      "[86/150][400/539]\tLoss_D: 0.2078\tLoss_G: 0.6962\n",
      "[86/150][450/539]\tLoss_D: 0.1310\tLoss_G: 0.6120\n",
      "[86/150][500/539]\tLoss_D: 0.0569\tLoss_G: 0.3381\n",
      "[87/150][0/539]\tLoss_D: 0.1889\tLoss_G: 0.2414\n",
      "[87/150][50/539]\tLoss_D: 0.0740\tLoss_G: 0.8357\n",
      "[87/150][100/539]\tLoss_D: 0.2274\tLoss_G: 0.5858\n",
      "[87/150][150/539]\tLoss_D: 0.1818\tLoss_G: 0.4019\n",
      "[87/150][200/539]\tLoss_D: 0.1686\tLoss_G: 0.7746\n",
      "[87/150][250/539]\tLoss_D: 0.1102\tLoss_G: 0.4228\n",
      "[87/150][300/539]\tLoss_D: 0.2411\tLoss_G: 0.5363\n",
      "[87/150][350/539]\tLoss_D: 0.0265\tLoss_G: 0.3136\n",
      "[87/150][400/539]\tLoss_D: 0.0562\tLoss_G: 0.5148\n",
      "[87/150][450/539]\tLoss_D: 0.0872\tLoss_G: 0.5877\n",
      "[87/150][500/539]\tLoss_D: 0.2398\tLoss_G: 0.4442\n",
      "[88/150][0/539]\tLoss_D: 0.1849\tLoss_G: 0.4794\n",
      "[88/150][50/539]\tLoss_D: 0.0991\tLoss_G: 0.4861\n",
      "[88/150][100/539]\tLoss_D: 0.1498\tLoss_G: 0.4398\n",
      "[88/150][150/539]\tLoss_D: 0.4054\tLoss_G: 0.9598\n",
      "[88/150][200/539]\tLoss_D: 0.0619\tLoss_G: 0.6072\n",
      "[88/150][250/539]\tLoss_D: 0.0940\tLoss_G: 0.5849\n",
      "[88/150][300/539]\tLoss_D: 0.2789\tLoss_G: 0.8089\n",
      "[88/150][350/539]\tLoss_D: 0.0720\tLoss_G: 0.4092\n",
      "[88/150][400/539]\tLoss_D: 0.0862\tLoss_G: 0.7181\n",
      "[88/150][450/539]\tLoss_D: 0.0918\tLoss_G: 0.7547\n",
      "[88/150][500/539]\tLoss_D: 0.2050\tLoss_G: 0.4192\n",
      "[89/150][0/539]\tLoss_D: 0.1628\tLoss_G: 0.4890\n",
      "[89/150][50/539]\tLoss_D: 0.0609\tLoss_G: 0.1634\n",
      "[89/150][100/539]\tLoss_D: 0.1389\tLoss_G: 0.6555\n",
      "[89/150][150/539]\tLoss_D: 0.0453\tLoss_G: 0.5746\n",
      "[89/150][200/539]\tLoss_D: 0.1342\tLoss_G: 0.8335\n",
      "[89/150][250/539]\tLoss_D: 0.0985\tLoss_G: 0.2735\n",
      "[89/150][300/539]\tLoss_D: 0.2074\tLoss_G: 0.3294\n",
      "[89/150][350/539]\tLoss_D: 0.0508\tLoss_G: 0.5589\n",
      "[89/150][400/539]\tLoss_D: 0.0887\tLoss_G: 0.5038\n",
      "[89/150][450/539]\tLoss_D: 0.1558\tLoss_G: 0.4561\n",
      "[89/150][500/539]\tLoss_D: 0.1258\tLoss_G: 0.3111\n",
      "[90/150][0/539]\tLoss_D: 0.2759\tLoss_G: 0.6150\n",
      "[90/150][50/539]\tLoss_D: 0.3805\tLoss_G: 0.5570\n",
      "[90/150][100/539]\tLoss_D: 0.1605\tLoss_G: 0.3847\n",
      "[90/150][150/539]\tLoss_D: 0.1000\tLoss_G: 0.4384\n",
      "[90/150][200/539]\tLoss_D: 0.2371\tLoss_G: 0.4213\n",
      "[90/150][250/539]\tLoss_D: 0.1282\tLoss_G: 0.5964\n",
      "[90/150][300/539]\tLoss_D: 0.2171\tLoss_G: 0.1116\n",
      "[90/150][350/539]\tLoss_D: 0.1533\tLoss_G: 0.5198\n",
      "[90/150][400/539]\tLoss_D: 0.2469\tLoss_G: 0.6123\n",
      "[90/150][450/539]\tLoss_D: 0.2229\tLoss_G: 0.5597\n",
      "[90/150][500/539]\tLoss_D: 0.1724\tLoss_G: 0.3983\n",
      "[91/150][0/539]\tLoss_D: 0.0283\tLoss_G: 0.3793\n",
      "[91/150][50/539]\tLoss_D: 0.0960\tLoss_G: 0.5710\n",
      "[91/150][100/539]\tLoss_D: 0.1197\tLoss_G: 0.4548\n",
      "[91/150][150/539]\tLoss_D: 0.2127\tLoss_G: 0.5805\n",
      "[91/150][200/539]\tLoss_D: 0.0398\tLoss_G: 0.4158\n",
      "[91/150][250/539]\tLoss_D: 0.0997\tLoss_G: 0.6025\n",
      "[91/150][300/539]\tLoss_D: 0.1137\tLoss_G: 0.1075\n",
      "[91/150][350/539]\tLoss_D: 0.3234\tLoss_G: 0.6549\n",
      "[91/150][400/539]\tLoss_D: 0.3552\tLoss_G: 0.4174\n",
      "[91/150][450/539]\tLoss_D: 0.1448\tLoss_G: 0.1858\n",
      "[91/150][500/539]\tLoss_D: 0.2677\tLoss_G: 0.5078\n",
      "[92/150][0/539]\tLoss_D: 0.1724\tLoss_G: 0.3790\n",
      "[92/150][50/539]\tLoss_D: 0.0786\tLoss_G: 0.4209\n",
      "[92/150][100/539]\tLoss_D: 0.1728\tLoss_G: 0.3245\n",
      "[92/150][150/539]\tLoss_D: 0.2958\tLoss_G: 0.2028\n",
      "[92/150][200/539]\tLoss_D: 0.3831\tLoss_G: 0.8256\n",
      "[92/150][250/539]\tLoss_D: 0.1292\tLoss_G: 0.6312\n",
      "[92/150][300/539]\tLoss_D: 0.0723\tLoss_G: 0.5002\n",
      "[92/150][350/539]\tLoss_D: 0.0712\tLoss_G: 0.6419\n",
      "[92/150][400/539]\tLoss_D: 0.1449\tLoss_G: 0.3501\n",
      "[92/150][450/539]\tLoss_D: 0.1091\tLoss_G: 0.5826\n",
      "[92/150][500/539]\tLoss_D: 0.0667\tLoss_G: 0.6176\n",
      "[93/150][0/539]\tLoss_D: 0.1956\tLoss_G: 0.3376\n",
      "[93/150][50/539]\tLoss_D: 0.1237\tLoss_G: 0.3378\n",
      "[93/150][100/539]\tLoss_D: 0.0367\tLoss_G: 0.6596\n",
      "[93/150][150/539]\tLoss_D: 0.0631\tLoss_G: 0.6041\n",
      "[93/150][200/539]\tLoss_D: 0.0561\tLoss_G: 0.8261\n",
      "[93/150][250/539]\tLoss_D: 0.3018\tLoss_G: 0.7637\n",
      "[93/150][300/539]\tLoss_D: 0.1542\tLoss_G: 0.3767\n",
      "[93/150][350/539]\tLoss_D: 0.0565\tLoss_G: 0.7053\n",
      "[93/150][400/539]\tLoss_D: 0.1263\tLoss_G: 1.2531\n",
      "[93/150][450/539]\tLoss_D: 0.2110\tLoss_G: 0.3487\n",
      "[93/150][500/539]\tLoss_D: 0.1574\tLoss_G: 0.2791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/150][0/539]\tLoss_D: 0.1820\tLoss_G: 0.2096\n",
      "[94/150][50/539]\tLoss_D: 0.0685\tLoss_G: 0.5250\n",
      "[94/150][100/539]\tLoss_D: 0.1192\tLoss_G: 0.4454\n",
      "[94/150][150/539]\tLoss_D: 0.3641\tLoss_G: 0.5067\n",
      "[94/150][200/539]\tLoss_D: 0.2179\tLoss_G: 0.4222\n",
      "[94/150][250/539]\tLoss_D: 0.2463\tLoss_G: 0.3820\n",
      "[94/150][300/539]\tLoss_D: 0.3638\tLoss_G: 0.7247\n",
      "[94/150][350/539]\tLoss_D: 0.2369\tLoss_G: 0.5307\n",
      "[94/150][400/539]\tLoss_D: 0.1043\tLoss_G: 0.4035\n",
      "[94/150][450/539]\tLoss_D: 0.0377\tLoss_G: 0.8831\n",
      "[94/150][500/539]\tLoss_D: 0.0378\tLoss_G: 0.4569\n",
      "[95/150][0/539]\tLoss_D: 0.2170\tLoss_G: 0.4979\n",
      "[95/150][50/539]\tLoss_D: 0.0164\tLoss_G: 1.0291\n",
      "[95/150][100/539]\tLoss_D: 0.2234\tLoss_G: 0.3363\n",
      "[95/150][150/539]\tLoss_D: 0.1694\tLoss_G: 0.9197\n",
      "[95/150][200/539]\tLoss_D: 0.3561\tLoss_G: 0.2866\n",
      "[95/150][250/539]\tLoss_D: 0.2574\tLoss_G: 0.3185\n",
      "[95/150][300/539]\tLoss_D: 0.4420\tLoss_G: 0.9638\n",
      "[95/150][350/539]\tLoss_D: 0.1057\tLoss_G: 0.5380\n",
      "[95/150][400/539]\tLoss_D: 0.0619\tLoss_G: 0.3692\n",
      "[95/150][450/539]\tLoss_D: 0.2153\tLoss_G: 0.5783\n",
      "[95/150][500/539]\tLoss_D: 0.2215\tLoss_G: 0.7194\n",
      "[96/150][0/539]\tLoss_D: 0.1639\tLoss_G: 0.8228\n",
      "[96/150][50/539]\tLoss_D: 0.0884\tLoss_G: 0.8728\n",
      "[96/150][100/539]\tLoss_D: 0.1152\tLoss_G: 0.4800\n",
      "[96/150][150/539]\tLoss_D: 0.2186\tLoss_G: 0.4625\n",
      "[96/150][200/539]\tLoss_D: 0.1306\tLoss_G: 0.5022\n",
      "[96/150][250/539]\tLoss_D: 0.2337\tLoss_G: 0.4404\n",
      "[96/150][300/539]\tLoss_D: 0.0950\tLoss_G: 0.5607\n",
      "[96/150][350/539]\tLoss_D: 0.2540\tLoss_G: 0.3232\n",
      "[96/150][400/539]\tLoss_D: 0.0875\tLoss_G: 0.3534\n",
      "[96/150][450/539]\tLoss_D: 0.3127\tLoss_G: 0.4019\n",
      "[96/150][500/539]\tLoss_D: 0.0431\tLoss_G: 0.7780\n",
      "[97/150][0/539]\tLoss_D: 0.0378\tLoss_G: 0.8477\n",
      "[97/150][50/539]\tLoss_D: 0.1269\tLoss_G: 0.5434\n",
      "[97/150][100/539]\tLoss_D: 0.0332\tLoss_G: 0.5448\n",
      "[97/150][150/539]\tLoss_D: 0.5313\tLoss_G: 0.7922\n",
      "[97/150][200/539]\tLoss_D: 0.1342\tLoss_G: 0.2841\n",
      "[97/150][250/539]\tLoss_D: 0.1305\tLoss_G: 0.5088\n",
      "[97/150][300/539]\tLoss_D: 0.2020\tLoss_G: 0.7147\n",
      "[97/150][350/539]\tLoss_D: 0.2137\tLoss_G: 0.5125\n",
      "[97/150][400/539]\tLoss_D: 0.0558\tLoss_G: 0.6139\n",
      "[97/150][450/539]\tLoss_D: 0.0748\tLoss_G: 0.3157\n",
      "[97/150][500/539]\tLoss_D: 0.1114\tLoss_G: 0.5234\n",
      "[98/150][0/539]\tLoss_D: 0.1473\tLoss_G: 0.4352\n",
      "[98/150][50/539]\tLoss_D: 0.0480\tLoss_G: 1.4465\n",
      "[98/150][100/539]\tLoss_D: 0.1943\tLoss_G: 0.8666\n",
      "[98/150][150/539]\tLoss_D: 0.3026\tLoss_G: 0.2079\n",
      "[98/150][200/539]\tLoss_D: 0.1629\tLoss_G: 0.6800\n",
      "[98/150][250/539]\tLoss_D: 0.2021\tLoss_G: 0.5020\n",
      "[98/150][300/539]\tLoss_D: 0.1838\tLoss_G: 0.3275\n",
      "[98/150][350/539]\tLoss_D: 0.0547\tLoss_G: 0.8738\n",
      "[98/150][400/539]\tLoss_D: 0.0499\tLoss_G: 0.6379\n",
      "[98/150][450/539]\tLoss_D: 0.0708\tLoss_G: 0.2838\n",
      "[98/150][500/539]\tLoss_D: 0.0417\tLoss_G: 1.1276\n",
      "[99/150][0/539]\tLoss_D: 0.0195\tLoss_G: 0.4259\n",
      "[99/150][50/539]\tLoss_D: 0.0883\tLoss_G: 0.4036\n",
      "[99/150][100/539]\tLoss_D: 0.0918\tLoss_G: 0.4781\n",
      "[99/150][150/539]\tLoss_D: 0.0962\tLoss_G: 0.2956\n",
      "[99/150][200/539]\tLoss_D: 0.0513\tLoss_G: 0.5540\n",
      "[99/150][250/539]\tLoss_D: 0.0651\tLoss_G: 0.5256\n",
      "[99/150][300/539]\tLoss_D: 0.1451\tLoss_G: 0.2097\n",
      "[99/150][350/539]\tLoss_D: 0.1151\tLoss_G: 0.4542\n",
      "[99/150][400/539]\tLoss_D: 0.1135\tLoss_G: 0.6222\n",
      "[99/150][450/539]\tLoss_D: 0.1481\tLoss_G: 0.6578\n",
      "[99/150][500/539]\tLoss_D: 0.0432\tLoss_G: 0.4039\n",
      "[100/150][0/539]\tLoss_D: 0.0983\tLoss_G: 0.5305\n",
      "[100/150][50/539]\tLoss_D: 0.0579\tLoss_G: 0.7814\n",
      "[100/150][100/539]\tLoss_D: 0.1045\tLoss_G: 1.0906\n",
      "[100/150][150/539]\tLoss_D: 0.2880\tLoss_G: 0.4561\n",
      "[100/150][200/539]\tLoss_D: 0.1212\tLoss_G: 0.4146\n",
      "[100/150][250/539]\tLoss_D: 0.0565\tLoss_G: 0.6708\n",
      "[100/150][300/539]\tLoss_D: 0.0818\tLoss_G: 0.5686\n",
      "[100/150][350/539]\tLoss_D: 0.3255\tLoss_G: 0.6086\n",
      "[100/150][400/539]\tLoss_D: 0.0992\tLoss_G: 0.6050\n",
      "[100/150][450/539]\tLoss_D: 0.0594\tLoss_G: 0.4500\n",
      "[100/150][500/539]\tLoss_D: 0.1406\tLoss_G: 0.3096\n",
      "[101/150][0/539]\tLoss_D: 0.2626\tLoss_G: 0.5054\n",
      "[101/150][50/539]\tLoss_D: 0.0609\tLoss_G: 0.7901\n",
      "[101/150][100/539]\tLoss_D: 0.2269\tLoss_G: 0.1293\n",
      "[101/150][150/539]\tLoss_D: 0.1729\tLoss_G: 0.5681\n",
      "[101/150][200/539]\tLoss_D: 0.0671\tLoss_G: 0.4491\n",
      "[101/150][250/539]\tLoss_D: 0.1743\tLoss_G: 0.7776\n",
      "[101/150][300/539]\tLoss_D: 0.2394\tLoss_G: 0.2961\n",
      "[101/150][350/539]\tLoss_D: 0.0462\tLoss_G: 0.4815\n",
      "[101/150][400/539]\tLoss_D: 0.0368\tLoss_G: 0.6120\n",
      "[101/150][450/539]\tLoss_D: 0.1464\tLoss_G: 0.4642\n",
      "[101/150][500/539]\tLoss_D: 0.1324\tLoss_G: 0.3820\n",
      "[102/150][0/539]\tLoss_D: 0.1547\tLoss_G: 0.5536\n",
      "[102/150][50/539]\tLoss_D: 0.2257\tLoss_G: 0.3974\n",
      "[102/150][100/539]\tLoss_D: 0.1994\tLoss_G: 0.2782\n",
      "[102/150][150/539]\tLoss_D: 0.1226\tLoss_G: 0.3799\n",
      "[102/150][200/539]\tLoss_D: 0.0376\tLoss_G: 0.6888\n",
      "[102/150][250/539]\tLoss_D: 0.2150\tLoss_G: 0.7505\n",
      "[102/150][300/539]\tLoss_D: 0.3953\tLoss_G: 0.3969\n",
      "[102/150][350/539]\tLoss_D: 0.0574\tLoss_G: 0.5192\n",
      "[102/150][400/539]\tLoss_D: 0.0661\tLoss_G: 0.4753\n",
      "[102/150][450/539]\tLoss_D: 0.1510\tLoss_G: 0.4944\n",
      "[102/150][500/539]\tLoss_D: 0.1555\tLoss_G: 0.5251\n",
      "[103/150][0/539]\tLoss_D: 0.1115\tLoss_G: 0.4565\n",
      "[103/150][50/539]\tLoss_D: 0.2717\tLoss_G: 0.3077\n",
      "[103/150][100/539]\tLoss_D: 0.2556\tLoss_G: 0.9532\n",
      "[103/150][150/539]\tLoss_D: 0.1716\tLoss_G: 0.8504\n",
      "[103/150][200/539]\tLoss_D: 0.3430\tLoss_G: 0.5900\n",
      "[103/150][250/539]\tLoss_D: 0.1055\tLoss_G: 0.5794\n",
      "[103/150][300/539]\tLoss_D: 0.2492\tLoss_G: 0.1069\n",
      "[103/150][350/539]\tLoss_D: 0.1696\tLoss_G: 0.3257\n",
      "[103/150][400/539]\tLoss_D: 0.0578\tLoss_G: 0.3604\n",
      "[103/150][450/539]\tLoss_D: 0.0425\tLoss_G: 0.5246\n",
      "[103/150][500/539]\tLoss_D: 0.1283\tLoss_G: 0.6769\n",
      "[104/150][0/539]\tLoss_D: 0.2126\tLoss_G: 0.5825\n",
      "[104/150][50/539]\tLoss_D: 0.0988\tLoss_G: 0.2174\n",
      "[104/150][100/539]\tLoss_D: 0.0624\tLoss_G: 0.3416\n",
      "[104/150][150/539]\tLoss_D: 0.1396\tLoss_G: 0.3385\n",
      "[104/150][200/539]\tLoss_D: 0.1640\tLoss_G: 0.2616\n",
      "[104/150][250/539]\tLoss_D: 0.0414\tLoss_G: 0.6546\n",
      "[104/150][300/539]\tLoss_D: 0.3005\tLoss_G: 0.2598\n",
      "[104/150][350/539]\tLoss_D: 0.2654\tLoss_G: 0.2238\n",
      "[104/150][400/539]\tLoss_D: 0.2438\tLoss_G: 0.4504\n",
      "[104/150][450/539]\tLoss_D: 0.1515\tLoss_G: 0.5734\n",
      "[104/150][500/539]\tLoss_D: 0.2233\tLoss_G: 0.5574\n",
      "[105/150][0/539]\tLoss_D: 0.1823\tLoss_G: 0.4275\n",
      "[105/150][50/539]\tLoss_D: 0.1044\tLoss_G: 0.3368\n",
      "[105/150][100/539]\tLoss_D: 0.0281\tLoss_G: 0.6487\n",
      "[105/150][150/539]\tLoss_D: 0.1079\tLoss_G: 0.6742\n",
      "[105/150][200/539]\tLoss_D: 0.1465\tLoss_G: 0.3272\n",
      "[105/150][250/539]\tLoss_D: 0.0839\tLoss_G: 0.4153\n",
      "[105/150][300/539]\tLoss_D: 0.0731\tLoss_G: 0.4941\n",
      "[105/150][350/539]\tLoss_D: 0.2007\tLoss_G: 0.7771\n",
      "[105/150][400/539]\tLoss_D: 0.1397\tLoss_G: 0.3519\n",
      "[105/150][450/539]\tLoss_D: 0.0564\tLoss_G: 0.4373\n",
      "[105/150][500/539]\tLoss_D: 0.0305\tLoss_G: 0.5939\n",
      "[106/150][0/539]\tLoss_D: 0.1948\tLoss_G: 0.6438\n",
      "[106/150][50/539]\tLoss_D: 0.2100\tLoss_G: 0.4549\n",
      "[106/150][100/539]\tLoss_D: 0.0556\tLoss_G: 0.3999\n",
      "[106/150][150/539]\tLoss_D: 0.1114\tLoss_G: 0.5096\n",
      "[106/150][200/539]\tLoss_D: 0.0319\tLoss_G: 0.4102\n",
      "[106/150][250/539]\tLoss_D: 0.3790\tLoss_G: 1.0166\n",
      "[106/150][300/539]\tLoss_D: 0.2236\tLoss_G: 0.6233\n",
      "[106/150][350/539]\tLoss_D: 0.1922\tLoss_G: 0.3474\n",
      "[106/150][400/539]\tLoss_D: 0.1192\tLoss_G: 0.1969\n",
      "[106/150][450/539]\tLoss_D: 0.0572\tLoss_G: 0.7931\n",
      "[106/150][500/539]\tLoss_D: 0.1754\tLoss_G: 0.4262\n",
      "[107/150][0/539]\tLoss_D: 0.3423\tLoss_G: 0.6097\n",
      "[107/150][50/539]\tLoss_D: 0.1978\tLoss_G: 0.7507\n",
      "[107/150][100/539]\tLoss_D: 0.3082\tLoss_G: 0.5786\n",
      "[107/150][150/539]\tLoss_D: 0.2893\tLoss_G: 0.5839\n",
      "[107/150][200/539]\tLoss_D: 0.2182\tLoss_G: 0.3355\n",
      "[107/150][250/539]\tLoss_D: 0.3263\tLoss_G: 0.4780\n",
      "[107/150][300/539]\tLoss_D: 0.0347\tLoss_G: 0.4825\n",
      "[107/150][350/539]\tLoss_D: 0.0440\tLoss_G: 0.5277\n",
      "[107/150][400/539]\tLoss_D: 0.0511\tLoss_G: 0.4798\n",
      "[107/150][450/539]\tLoss_D: 0.0843\tLoss_G: 0.8719\n",
      "[107/150][500/539]\tLoss_D: 0.0457\tLoss_G: 0.5267\n",
      "[108/150][0/539]\tLoss_D: 0.2230\tLoss_G: 0.3954\n",
      "[108/150][50/539]\tLoss_D: 0.1540\tLoss_G: 0.2834\n",
      "[108/150][100/539]\tLoss_D: 0.2509\tLoss_G: 0.6013\n",
      "[108/150][150/539]\tLoss_D: 0.1057\tLoss_G: 0.4388\n",
      "[108/150][200/539]\tLoss_D: 0.1188\tLoss_G: 0.4864\n",
      "[108/150][250/539]\tLoss_D: 0.2851\tLoss_G: 0.6859\n",
      "[108/150][300/539]\tLoss_D: 0.1560\tLoss_G: 0.4737\n",
      "[108/150][350/539]\tLoss_D: 0.2252\tLoss_G: 0.2187\n",
      "[108/150][400/539]\tLoss_D: 0.1294\tLoss_G: 0.4864\n",
      "[108/150][450/539]\tLoss_D: 0.2394\tLoss_G: 0.4245\n",
      "[108/150][500/539]\tLoss_D: 0.1952\tLoss_G: 0.1940\n",
      "[109/150][0/539]\tLoss_D: 0.2120\tLoss_G: 0.3764\n",
      "[109/150][50/539]\tLoss_D: 0.4480\tLoss_G: 0.5165\n",
      "[109/150][100/539]\tLoss_D: 0.1887\tLoss_G: 0.4814\n",
      "[109/150][150/539]\tLoss_D: 0.0367\tLoss_G: 0.4678\n",
      "[109/150][200/539]\tLoss_D: 0.1427\tLoss_G: 0.5069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109/150][250/539]\tLoss_D: 0.3676\tLoss_G: 0.5936\n",
      "[109/150][300/539]\tLoss_D: 0.0960\tLoss_G: 0.3135\n",
      "[109/150][350/539]\tLoss_D: 0.1678\tLoss_G: 0.6914\n",
      "[109/150][400/539]\tLoss_D: 0.1210\tLoss_G: 0.3852\n",
      "[109/150][450/539]\tLoss_D: 0.1481\tLoss_G: 0.4217\n",
      "[109/150][500/539]\tLoss_D: 0.0384\tLoss_G: 0.7159\n",
      "[110/150][0/539]\tLoss_D: 0.1343\tLoss_G: 0.4003\n",
      "[110/150][50/539]\tLoss_D: 0.1013\tLoss_G: 0.5561\n",
      "[110/150][100/539]\tLoss_D: 0.2052\tLoss_G: 0.3969\n",
      "[110/150][150/539]\tLoss_D: 0.2076\tLoss_G: 0.2985\n",
      "[110/150][200/539]\tLoss_D: 0.1525\tLoss_G: 0.7378\n",
      "[110/150][250/539]\tLoss_D: 0.1166\tLoss_G: 0.5305\n",
      "[110/150][300/539]\tLoss_D: 0.0444\tLoss_G: 0.6110\n",
      "[110/150][350/539]\tLoss_D: 0.1551\tLoss_G: 0.4632\n",
      "[110/150][400/539]\tLoss_D: 0.0347\tLoss_G: 0.6328\n",
      "[110/150][450/539]\tLoss_D: 0.0818\tLoss_G: 0.4544\n",
      "[110/150][500/539]\tLoss_D: 0.2349\tLoss_G: 0.6855\n",
      "[111/150][0/539]\tLoss_D: 0.1612\tLoss_G: 0.4323\n",
      "[111/150][50/539]\tLoss_D: 0.2753\tLoss_G: 0.4413\n",
      "[111/150][100/539]\tLoss_D: 0.1579\tLoss_G: 0.3394\n",
      "[111/150][150/539]\tLoss_D: 0.0806\tLoss_G: 0.5801\n",
      "[111/150][200/539]\tLoss_D: 0.0841\tLoss_G: 0.4657\n",
      "[111/150][250/539]\tLoss_D: 0.0375\tLoss_G: 0.4670\n",
      "[111/150][300/539]\tLoss_D: 0.0757\tLoss_G: 0.5702\n",
      "[111/150][350/539]\tLoss_D: 0.1660\tLoss_G: 0.2298\n",
      "[111/150][400/539]\tLoss_D: 0.2725\tLoss_G: 0.4977\n",
      "[111/150][450/539]\tLoss_D: 0.2235\tLoss_G: 0.5522\n",
      "[111/150][500/539]\tLoss_D: 0.1093\tLoss_G: 0.2729\n",
      "[112/150][0/539]\tLoss_D: 0.1986\tLoss_G: 0.4748\n",
      "[112/150][50/539]\tLoss_D: 0.1058\tLoss_G: 0.3047\n",
      "[112/150][100/539]\tLoss_D: 0.2019\tLoss_G: 0.4304\n",
      "[112/150][150/539]\tLoss_D: 0.0829\tLoss_G: 0.5324\n",
      "[112/150][200/539]\tLoss_D: 0.1387\tLoss_G: 0.1643\n",
      "[112/150][250/539]\tLoss_D: 0.0742\tLoss_G: 0.9250\n",
      "[112/150][300/539]\tLoss_D: 0.3037\tLoss_G: 0.6463\n",
      "[112/150][350/539]\tLoss_D: 0.0989\tLoss_G: 0.4076\n",
      "[112/150][400/539]\tLoss_D: 0.0567\tLoss_G: 0.2807\n",
      "[112/150][450/539]\tLoss_D: 0.0663\tLoss_G: 0.7079\n",
      "[112/150][500/539]\tLoss_D: 0.1737\tLoss_G: 0.5246\n",
      "[113/150][0/539]\tLoss_D: 0.0895\tLoss_G: 0.6342\n",
      "[113/150][50/539]\tLoss_D: 0.0572\tLoss_G: 0.7027\n",
      "[113/150][100/539]\tLoss_D: 0.0936\tLoss_G: 0.4429\n",
      "[113/150][150/539]\tLoss_D: 0.1147\tLoss_G: 0.4199\n",
      "[113/150][200/539]\tLoss_D: 0.1100\tLoss_G: 0.6500\n",
      "[113/150][250/539]\tLoss_D: 0.2759\tLoss_G: 0.5219\n",
      "[113/150][300/539]\tLoss_D: 0.0423\tLoss_G: 0.5866\n",
      "[113/150][350/539]\tLoss_D: 0.0476\tLoss_G: 0.6242\n",
      "[113/150][400/539]\tLoss_D: 0.3171\tLoss_G: 0.3646\n",
      "[113/150][450/539]\tLoss_D: 0.3182\tLoss_G: 0.5294\n",
      "[113/150][500/539]\tLoss_D: 0.0912\tLoss_G: 0.4771\n",
      "[114/150][0/539]\tLoss_D: 0.0590\tLoss_G: 0.5162\n",
      "[114/150][50/539]\tLoss_D: 0.0330\tLoss_G: 0.6864\n",
      "[114/150][100/539]\tLoss_D: 0.1894\tLoss_G: 0.3633\n",
      "[114/150][150/539]\tLoss_D: 0.2376\tLoss_G: 0.3366\n",
      "[114/150][200/539]\tLoss_D: 0.1085\tLoss_G: 0.3460\n",
      "[114/150][250/539]\tLoss_D: 0.0930\tLoss_G: 0.3590\n",
      "[114/150][300/539]\tLoss_D: 0.1583\tLoss_G: 0.2471\n",
      "[114/150][350/539]\tLoss_D: 0.2433\tLoss_G: 0.6176\n",
      "[114/150][400/539]\tLoss_D: 0.1285\tLoss_G: 0.5640\n",
      "[114/150][450/539]\tLoss_D: 0.0774\tLoss_G: 0.2716\n",
      "[114/150][500/539]\tLoss_D: 0.1680\tLoss_G: 0.6158\n",
      "[115/150][0/539]\tLoss_D: 0.1006\tLoss_G: 0.3140\n",
      "[115/150][50/539]\tLoss_D: 0.2293\tLoss_G: 0.4393\n",
      "[115/150][100/539]\tLoss_D: 0.1855\tLoss_G: 0.5673\n",
      "[115/150][150/539]\tLoss_D: 0.1817\tLoss_G: 0.3213\n",
      "[115/150][200/539]\tLoss_D: 0.0573\tLoss_G: 0.4743\n",
      "[115/150][250/539]\tLoss_D: 0.0847\tLoss_G: 0.5109\n",
      "[115/150][300/539]\tLoss_D: 0.1732\tLoss_G: 0.6669\n",
      "[115/150][350/539]\tLoss_D: 0.2319\tLoss_G: 0.3641\n",
      "[115/150][400/539]\tLoss_D: 0.1122\tLoss_G: 0.3699\n",
      "[115/150][450/539]\tLoss_D: 0.0578\tLoss_G: 0.5750\n",
      "[115/150][500/539]\tLoss_D: 0.0502\tLoss_G: 1.0477\n",
      "[116/150][0/539]\tLoss_D: 0.5015\tLoss_G: 0.2443\n",
      "[116/150][50/539]\tLoss_D: 0.1250\tLoss_G: 0.7228\n",
      "[116/150][100/539]\tLoss_D: 0.3235\tLoss_G: 0.5145\n",
      "[116/150][150/539]\tLoss_D: 0.0580\tLoss_G: 1.0845\n",
      "[116/150][200/539]\tLoss_D: 0.1286\tLoss_G: 0.6526\n",
      "[116/150][250/539]\tLoss_D: 0.1583\tLoss_G: 0.2363\n",
      "[116/150][300/539]\tLoss_D: 0.1549\tLoss_G: 0.3312\n",
      "[116/150][350/539]\tLoss_D: 0.4444\tLoss_G: 0.5559\n",
      "[116/150][400/539]\tLoss_D: 0.1778\tLoss_G: 0.7238\n",
      "[116/150][450/539]\tLoss_D: 0.1232\tLoss_G: 0.4093\n",
      "[116/150][500/539]\tLoss_D: 0.0492\tLoss_G: 0.5224\n",
      "[117/150][0/539]\tLoss_D: 0.0354\tLoss_G: 0.7846\n",
      "[117/150][50/539]\tLoss_D: 0.3004\tLoss_G: 0.6837\n",
      "[117/150][100/539]\tLoss_D: 0.2197\tLoss_G: 0.4333\n",
      "[117/150][150/539]\tLoss_D: 0.2230\tLoss_G: 0.4788\n",
      "[117/150][200/539]\tLoss_D: 0.2752\tLoss_G: 0.3586\n",
      "[117/150][250/539]\tLoss_D: 0.3058\tLoss_G: 0.3550\n",
      "[117/150][300/539]\tLoss_D: 0.3367\tLoss_G: 0.2647\n",
      "[117/150][350/539]\tLoss_D: 0.1649\tLoss_G: 0.5846\n",
      "[117/150][400/539]\tLoss_D: 0.0904\tLoss_G: 0.5745\n",
      "[117/150][450/539]\tLoss_D: 0.1970\tLoss_G: 0.5021\n",
      "[117/150][500/539]\tLoss_D: 0.0212\tLoss_G: 0.4286\n",
      "[118/150][0/539]\tLoss_D: 0.1718\tLoss_G: 0.1522\n",
      "[118/150][50/539]\tLoss_D: 0.0593\tLoss_G: 0.4094\n",
      "[118/150][100/539]\tLoss_D: 0.1515\tLoss_G: 0.3883\n",
      "[118/150][150/539]\tLoss_D: 0.2708\tLoss_G: 0.5266\n",
      "[118/150][200/539]\tLoss_D: 0.0438\tLoss_G: 0.6030\n",
      "[118/150][250/539]\tLoss_D: 0.2903\tLoss_G: 0.2887\n",
      "[118/150][300/539]\tLoss_D: 0.3678\tLoss_G: 0.4854\n",
      "[118/150][350/539]\tLoss_D: 0.2396\tLoss_G: 0.3882\n",
      "[118/150][400/539]\tLoss_D: 0.0762\tLoss_G: 0.3861\n",
      "[118/150][450/539]\tLoss_D: 0.4313\tLoss_G: 0.5627\n",
      "[118/150][500/539]\tLoss_D: 0.1355\tLoss_G: 0.6842\n",
      "[119/150][0/539]\tLoss_D: 0.2400\tLoss_G: 0.1567\n",
      "[119/150][50/539]\tLoss_D: 0.2703\tLoss_G: 0.5008\n",
      "[119/150][100/539]\tLoss_D: 0.3817\tLoss_G: 0.6880\n",
      "[119/150][150/539]\tLoss_D: 0.0842\tLoss_G: 0.4273\n",
      "[119/150][200/539]\tLoss_D: 0.0669\tLoss_G: 0.2907\n",
      "[119/150][250/539]\tLoss_D: 0.2285\tLoss_G: 0.4794\n",
      "[119/150][300/539]\tLoss_D: 0.3465\tLoss_G: 0.1948\n",
      "[119/150][350/539]\tLoss_D: 0.3089\tLoss_G: 0.5182\n",
      "[119/150][400/539]\tLoss_D: 0.1765\tLoss_G: 0.4729\n",
      "[119/150][450/539]\tLoss_D: 0.0865\tLoss_G: 0.3575\n",
      "[119/150][500/539]\tLoss_D: 0.2232\tLoss_G: 0.4148\n",
      "[120/150][0/539]\tLoss_D: 0.0161\tLoss_G: 0.6668\n",
      "[120/150][50/539]\tLoss_D: 0.0394\tLoss_G: 0.4714\n",
      "[120/150][100/539]\tLoss_D: 0.1132\tLoss_G: 0.6920\n",
      "[120/150][150/539]\tLoss_D: 0.0307\tLoss_G: 0.9462\n",
      "[120/150][200/539]\tLoss_D: 0.2469\tLoss_G: 0.3690\n",
      "[120/150][250/539]\tLoss_D: 0.0940\tLoss_G: 0.5496\n",
      "[120/150][300/539]\tLoss_D: 0.0426\tLoss_G: 0.2821\n",
      "[120/150][350/539]\tLoss_D: 0.1289\tLoss_G: 0.4421\n",
      "[120/150][400/539]\tLoss_D: 0.3315\tLoss_G: 0.4072\n",
      "[120/150][450/539]\tLoss_D: 0.0519\tLoss_G: 0.4676\n",
      "[120/150][500/539]\tLoss_D: 0.2115\tLoss_G: 0.0944\n",
      "[121/150][0/539]\tLoss_D: 0.0461\tLoss_G: 0.5679\n",
      "[121/150][50/539]\tLoss_D: 0.1732\tLoss_G: 0.3204\n",
      "[121/150][100/539]\tLoss_D: 0.0959\tLoss_G: 0.7577\n",
      "[121/150][150/539]\tLoss_D: 0.3455\tLoss_G: 0.4186\n",
      "[121/150][200/539]\tLoss_D: 0.1406\tLoss_G: 0.4049\n",
      "[121/150][250/539]\tLoss_D: 0.1012\tLoss_G: 0.2806\n",
      "[121/150][300/539]\tLoss_D: 0.1347\tLoss_G: 0.5211\n",
      "[121/150][350/539]\tLoss_D: 0.1137\tLoss_G: 0.3622\n",
      "[121/150][400/539]\tLoss_D: 0.2601\tLoss_G: 0.0715\n",
      "[121/150][450/539]\tLoss_D: 0.3525\tLoss_G: 0.3237\n",
      "[121/150][500/539]\tLoss_D: 0.3623\tLoss_G: 0.6913\n",
      "[122/150][0/539]\tLoss_D: 0.3880\tLoss_G: 0.3535\n",
      "[122/150][50/539]\tLoss_D: 0.1852\tLoss_G: 0.5279\n",
      "[122/150][100/539]\tLoss_D: 0.0948\tLoss_G: 0.4663\n",
      "[122/150][150/539]\tLoss_D: 0.0767\tLoss_G: 0.4626\n",
      "[122/150][200/539]\tLoss_D: 0.0430\tLoss_G: 0.6949\n",
      "[122/150][250/539]\tLoss_D: 0.0719\tLoss_G: 0.5049\n",
      "[122/150][300/539]\tLoss_D: 0.1229\tLoss_G: 0.5461\n",
      "[122/150][350/539]\tLoss_D: 0.1397\tLoss_G: 0.3109\n",
      "[122/150][400/539]\tLoss_D: 0.0565\tLoss_G: 0.6125\n",
      "[122/150][450/539]\tLoss_D: 0.1830\tLoss_G: 0.3871\n",
      "[122/150][500/539]\tLoss_D: 0.2959\tLoss_G: 0.6548\n",
      "[123/150][0/539]\tLoss_D: 0.1116\tLoss_G: 0.6381\n",
      "[123/150][50/539]\tLoss_D: 0.2908\tLoss_G: 0.4252\n",
      "[123/150][100/539]\tLoss_D: 0.2778\tLoss_G: 0.4635\n",
      "[123/150][150/539]\tLoss_D: 0.0496\tLoss_G: 0.3772\n",
      "[123/150][200/539]\tLoss_D: 0.3453\tLoss_G: 0.5618\n",
      "[123/150][250/539]\tLoss_D: 0.2081\tLoss_G: 0.4663\n",
      "[123/150][300/539]\tLoss_D: 0.2923\tLoss_G: 0.8677\n",
      "[123/150][350/539]\tLoss_D: 0.4143\tLoss_G: 0.4496\n",
      "[123/150][400/539]\tLoss_D: 0.1435\tLoss_G: 0.9904\n",
      "[123/150][450/539]\tLoss_D: 0.0726\tLoss_G: 0.2381\n",
      "[123/150][500/539]\tLoss_D: 0.0833\tLoss_G: 0.9130\n",
      "[124/150][0/539]\tLoss_D: 0.0871\tLoss_G: 0.4234\n",
      "[124/150][50/539]\tLoss_D: 0.1102\tLoss_G: 0.4912\n",
      "[124/150][100/539]\tLoss_D: 0.2760\tLoss_G: 0.2826\n",
      "[124/150][150/539]\tLoss_D: 0.1658\tLoss_G: 0.2068\n",
      "[124/150][200/539]\tLoss_D: 0.0593\tLoss_G: 0.3780\n",
      "[124/150][250/539]\tLoss_D: 0.2173\tLoss_G: 0.3493\n",
      "[124/150][300/539]\tLoss_D: 0.5417\tLoss_G: 0.2005\n",
      "[124/150][350/539]\tLoss_D: 0.1959\tLoss_G: 0.7762\n",
      "[124/150][400/539]\tLoss_D: 0.0930\tLoss_G: 0.6032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124/150][450/539]\tLoss_D: 0.2820\tLoss_G: 0.5490\n",
      "[124/150][500/539]\tLoss_D: 0.1906\tLoss_G: 0.7142\n",
      "[125/150][0/539]\tLoss_D: 0.3285\tLoss_G: 0.5216\n",
      "[125/150][50/539]\tLoss_D: 0.1377\tLoss_G: 0.4804\n",
      "[125/150][100/539]\tLoss_D: 0.0458\tLoss_G: 0.3930\n",
      "[125/150][150/539]\tLoss_D: 0.1950\tLoss_G: 0.4823\n",
      "[125/150][200/539]\tLoss_D: 0.1267\tLoss_G: 0.4676\n",
      "[125/150][250/539]\tLoss_D: 0.0458\tLoss_G: 0.3900\n",
      "[125/150][300/539]\tLoss_D: 0.2169\tLoss_G: 0.5834\n",
      "[125/150][350/539]\tLoss_D: 0.0505\tLoss_G: 0.5970\n",
      "[125/150][400/539]\tLoss_D: 0.1835\tLoss_G: 0.5989\n",
      "[125/150][450/539]\tLoss_D: 0.2502\tLoss_G: 0.6629\n",
      "[125/150][500/539]\tLoss_D: 0.3773\tLoss_G: 0.5622\n",
      "[126/150][0/539]\tLoss_D: 0.3148\tLoss_G: 0.2293\n",
      "[126/150][50/539]\tLoss_D: 0.2643\tLoss_G: 0.2475\n",
      "[126/150][100/539]\tLoss_D: 0.3984\tLoss_G: 0.6085\n",
      "[126/150][150/539]\tLoss_D: 0.0821\tLoss_G: 0.4636\n",
      "[126/150][200/539]\tLoss_D: 0.0827\tLoss_G: 0.5199\n",
      "[126/150][250/539]\tLoss_D: 0.1297\tLoss_G: 0.3940\n",
      "[126/150][300/539]\tLoss_D: 0.1360\tLoss_G: 0.7055\n",
      "[126/150][350/539]\tLoss_D: 0.1909\tLoss_G: 0.3908\n",
      "[126/150][400/539]\tLoss_D: 0.1440\tLoss_G: 0.2464\n",
      "[126/150][450/539]\tLoss_D: 0.0470\tLoss_G: 0.8493\n",
      "[126/150][500/539]\tLoss_D: 0.1330\tLoss_G: 0.4802\n",
      "[127/150][0/539]\tLoss_D: 0.1355\tLoss_G: 0.5224\n",
      "[127/150][50/539]\tLoss_D: 0.0633\tLoss_G: 0.3268\n",
      "[127/150][100/539]\tLoss_D: 0.1966\tLoss_G: 0.5183\n",
      "[127/150][150/539]\tLoss_D: 0.3084\tLoss_G: 0.7187\n",
      "[127/150][200/539]\tLoss_D: 0.1350\tLoss_G: 0.3976\n",
      "[127/150][250/539]\tLoss_D: 0.0616\tLoss_G: 0.3029\n",
      "[127/150][300/539]\tLoss_D: 0.1234\tLoss_G: 0.7820\n",
      "[127/150][350/539]\tLoss_D: 0.1678\tLoss_G: 0.5458\n",
      "[127/150][400/539]\tLoss_D: 0.1193\tLoss_G: 0.1552\n",
      "[127/150][450/539]\tLoss_D: 0.1034\tLoss_G: 0.8471\n",
      "[127/150][500/539]\tLoss_D: 0.0385\tLoss_G: 0.5737\n",
      "[128/150][0/539]\tLoss_D: 0.1758\tLoss_G: 0.3544\n",
      "[128/150][50/539]\tLoss_D: 0.1616\tLoss_G: 0.2568\n",
      "[128/150][100/539]\tLoss_D: 0.0266\tLoss_G: 0.5227\n",
      "[128/150][150/539]\tLoss_D: 0.0606\tLoss_G: 0.4148\n",
      "[128/150][200/539]\tLoss_D: 0.4028\tLoss_G: 0.4816\n",
      "[128/150][250/539]\tLoss_D: 0.0641\tLoss_G: 0.7193\n",
      "[128/150][300/539]\tLoss_D: 0.3262\tLoss_G: 0.7445\n",
      "[128/150][350/539]\tLoss_D: 0.0969\tLoss_G: 0.8130\n",
      "[128/150][400/539]\tLoss_D: 0.2783\tLoss_G: 0.3181\n",
      "[128/150][450/539]\tLoss_D: 0.0857\tLoss_G: 0.4861\n",
      "[128/150][500/539]\tLoss_D: 0.0940\tLoss_G: 0.7976\n",
      "[129/150][0/539]\tLoss_D: 0.0658\tLoss_G: 0.3536\n",
      "[129/150][50/539]\tLoss_D: 0.1220\tLoss_G: 0.4009\n",
      "[129/150][100/539]\tLoss_D: 0.0932\tLoss_G: 0.7395\n",
      "[129/150][150/539]\tLoss_D: 0.1309\tLoss_G: 0.5870\n",
      "[129/150][200/539]\tLoss_D: 0.3497\tLoss_G: 0.2580\n",
      "[129/150][250/539]\tLoss_D: 0.4013\tLoss_G: 0.5105\n",
      "[129/150][300/539]\tLoss_D: 0.1195\tLoss_G: 0.2033\n",
      "[129/150][350/539]\tLoss_D: 0.0814\tLoss_G: 0.4069\n",
      "[129/150][400/539]\tLoss_D: 0.1011\tLoss_G: 0.7257\n",
      "[129/150][450/539]\tLoss_D: 0.1958\tLoss_G: 0.4514\n",
      "[129/150][500/539]\tLoss_D: 0.2813\tLoss_G: 0.5145\n",
      "[130/150][0/539]\tLoss_D: 0.2650\tLoss_G: 0.4065\n",
      "[130/150][50/539]\tLoss_D: 0.1670\tLoss_G: 0.3239\n",
      "[130/150][100/539]\tLoss_D: 0.1374\tLoss_G: 0.5045\n",
      "[130/150][150/539]\tLoss_D: 0.0748\tLoss_G: 0.7677\n",
      "[130/150][200/539]\tLoss_D: 0.4119\tLoss_G: 0.4492\n",
      "[130/150][250/539]\tLoss_D: 0.1013\tLoss_G: 0.3139\n",
      "[130/150][300/539]\tLoss_D: 0.1398\tLoss_G: 0.5391\n",
      "[130/150][350/539]\tLoss_D: 0.1769\tLoss_G: 0.7490\n",
      "[130/150][400/539]\tLoss_D: 0.0735\tLoss_G: 0.3779\n",
      "[130/150][450/539]\tLoss_D: 0.1070\tLoss_G: 0.4414\n",
      "[130/150][500/539]\tLoss_D: 0.1176\tLoss_G: 0.5433\n",
      "[131/150][0/539]\tLoss_D: 0.2391\tLoss_G: 0.5911\n",
      "[131/150][50/539]\tLoss_D: 0.2484\tLoss_G: 0.7478\n",
      "[131/150][100/539]\tLoss_D: 0.3160\tLoss_G: 0.2709\n",
      "[131/150][150/539]\tLoss_D: 0.0341\tLoss_G: 1.0066\n",
      "[131/150][200/539]\tLoss_D: 0.0902\tLoss_G: 0.2273\n",
      "[131/150][250/539]\tLoss_D: 0.1945\tLoss_G: 0.6044\n",
      "[131/150][300/539]\tLoss_D: 0.0532\tLoss_G: 0.5842\n",
      "[131/150][350/539]\tLoss_D: 0.0889\tLoss_G: 0.1632\n",
      "[131/150][400/539]\tLoss_D: 0.1257\tLoss_G: 0.2668\n",
      "[131/150][450/539]\tLoss_D: 0.0489\tLoss_G: 0.4444\n",
      "[131/150][500/539]\tLoss_D: 0.0518\tLoss_G: 0.5526\n",
      "[132/150][0/539]\tLoss_D: 0.2241\tLoss_G: 0.2068\n",
      "[132/150][50/539]\tLoss_D: 0.1463\tLoss_G: 0.4890\n",
      "[132/150][100/539]\tLoss_D: 0.2821\tLoss_G: 0.4277\n",
      "[132/150][150/539]\tLoss_D: 0.1016\tLoss_G: 0.5436\n",
      "[132/150][200/539]\tLoss_D: 0.1286\tLoss_G: 0.4233\n",
      "[132/150][250/539]\tLoss_D: 0.3989\tLoss_G: 0.1360\n",
      "[132/150][300/539]\tLoss_D: 0.0761\tLoss_G: 0.3467\n",
      "[132/150][350/539]\tLoss_D: 0.0798\tLoss_G: 0.4971\n",
      "[132/150][400/539]\tLoss_D: 0.2764\tLoss_G: 0.4216\n",
      "[132/150][450/539]\tLoss_D: 0.0291\tLoss_G: 0.8409\n",
      "[132/150][500/539]\tLoss_D: 0.2712\tLoss_G: 0.4699\n",
      "[133/150][0/539]\tLoss_D: 0.1994\tLoss_G: 0.2231\n",
      "[133/150][50/539]\tLoss_D: 0.0990\tLoss_G: 0.4431\n",
      "[133/150][100/539]\tLoss_D: 0.1915\tLoss_G: 0.4208\n",
      "[133/150][150/539]\tLoss_D: 0.1467\tLoss_G: 1.2205\n",
      "[133/150][200/539]\tLoss_D: 0.0696\tLoss_G: 0.4289\n",
      "[133/150][250/539]\tLoss_D: 0.0545\tLoss_G: 0.4534\n",
      "[133/150][300/539]\tLoss_D: 0.1080\tLoss_G: 0.4701\n",
      "[133/150][350/539]\tLoss_D: 0.0581\tLoss_G: 0.5928\n",
      "[133/150][400/539]\tLoss_D: 0.2708\tLoss_G: 0.4176\n",
      "[133/150][450/539]\tLoss_D: 0.0861\tLoss_G: 0.4367\n",
      "[133/150][500/539]\tLoss_D: 0.2201\tLoss_G: 0.3033\n",
      "[134/150][0/539]\tLoss_D: 0.1917\tLoss_G: 0.2915\n",
      "[134/150][50/539]\tLoss_D: 0.2429\tLoss_G: 0.3175\n",
      "[134/150][100/539]\tLoss_D: 0.1023\tLoss_G: 0.3545\n",
      "[134/150][150/539]\tLoss_D: 0.2521\tLoss_G: 0.3771\n",
      "[134/150][200/539]\tLoss_D: 0.2000\tLoss_G: 0.3819\n",
      "[134/150][250/539]\tLoss_D: 0.2484\tLoss_G: 0.4886\n",
      "[134/150][300/539]\tLoss_D: 0.1151\tLoss_G: 0.3110\n",
      "[134/150][350/539]\tLoss_D: 0.3507\tLoss_G: 0.3761\n",
      "[134/150][400/539]\tLoss_D: 0.2176\tLoss_G: 0.4796\n",
      "[134/150][450/539]\tLoss_D: 0.3059\tLoss_G: 0.2940\n",
      "[134/150][500/539]\tLoss_D: 0.4611\tLoss_G: 0.2489\n",
      "[135/150][0/539]\tLoss_D: 0.0445\tLoss_G: 0.4225\n",
      "[135/150][50/539]\tLoss_D: 0.2558\tLoss_G: 0.1586\n",
      "[135/150][100/539]\tLoss_D: 0.4234\tLoss_G: 0.4140\n",
      "[135/150][150/539]\tLoss_D: 0.3012\tLoss_G: 0.4937\n",
      "[135/150][200/539]\tLoss_D: 0.1281\tLoss_G: 0.5626\n",
      "[135/150][250/539]\tLoss_D: 0.2500\tLoss_G: 0.3429\n",
      "[135/150][300/539]\tLoss_D: 0.3040\tLoss_G: 0.7265\n",
      "[135/150][350/539]\tLoss_D: 0.1460\tLoss_G: 0.4348\n",
      "[135/150][400/539]\tLoss_D: 0.0945\tLoss_G: 0.4040\n",
      "[135/150][450/539]\tLoss_D: 0.2394\tLoss_G: 0.5144\n",
      "[135/150][500/539]\tLoss_D: 0.1290\tLoss_G: 0.4541\n",
      "[136/150][0/539]\tLoss_D: 0.0393\tLoss_G: 0.5686\n",
      "[136/150][50/539]\tLoss_D: 0.1789\tLoss_G: 0.6183\n",
      "[136/150][100/539]\tLoss_D: 0.1633\tLoss_G: 0.5210\n",
      "[136/150][150/539]\tLoss_D: 0.0919\tLoss_G: 0.4865\n",
      "[136/150][200/539]\tLoss_D: 0.0968\tLoss_G: 0.3388\n",
      "[136/150][250/539]\tLoss_D: 0.1808\tLoss_G: 0.5117\n",
      "[136/150][300/539]\tLoss_D: 0.0782\tLoss_G: 0.3259\n",
      "[136/150][350/539]\tLoss_D: 0.0761\tLoss_G: 0.2782\n",
      "[136/150][400/539]\tLoss_D: 0.0663\tLoss_G: 0.6027\n",
      "[136/150][450/539]\tLoss_D: 0.1375\tLoss_G: 0.3805\n",
      "[136/150][500/539]\tLoss_D: 0.1399\tLoss_G: 0.7050\n",
      "[137/150][0/539]\tLoss_D: 0.1776\tLoss_G: 0.5683\n",
      "[137/150][50/539]\tLoss_D: 0.0149\tLoss_G: 0.8725\n",
      "[137/150][100/539]\tLoss_D: 0.2557\tLoss_G: 0.7986\n",
      "[137/150][150/539]\tLoss_D: 0.3882\tLoss_G: 0.3957\n",
      "[137/150][200/539]\tLoss_D: 0.1274\tLoss_G: 0.4244\n",
      "[137/150][250/539]\tLoss_D: 0.0764\tLoss_G: 0.5735\n",
      "[137/150][300/539]\tLoss_D: 0.1184\tLoss_G: 0.2717\n",
      "[137/150][350/539]\tLoss_D: 0.0694\tLoss_G: 0.5861\n",
      "[137/150][400/539]\tLoss_D: 0.3655\tLoss_G: 0.5789\n",
      "[137/150][450/539]\tLoss_D: 0.1246\tLoss_G: 0.5778\n",
      "[137/150][500/539]\tLoss_D: 0.2338\tLoss_G: 0.3025\n",
      "[138/150][0/539]\tLoss_D: 0.2818\tLoss_G: 0.5029\n",
      "[138/150][50/539]\tLoss_D: 0.1584\tLoss_G: 0.1628\n",
      "[138/150][100/539]\tLoss_D: 0.0796\tLoss_G: 0.5305\n",
      "[138/150][150/539]\tLoss_D: 0.0644\tLoss_G: 0.5997\n",
      "[138/150][200/539]\tLoss_D: 0.0945\tLoss_G: 0.5604\n",
      "[138/150][250/539]\tLoss_D: 0.0577\tLoss_G: 0.4078\n",
      "[138/150][300/539]\tLoss_D: 0.0806\tLoss_G: 0.3727\n",
      "[138/150][350/539]\tLoss_D: 0.0915\tLoss_G: 0.4672\n",
      "[138/150][400/539]\tLoss_D: 0.1731\tLoss_G: 0.4284\n",
      "[138/150][450/539]\tLoss_D: 0.2357\tLoss_G: 0.2400\n",
      "[138/150][500/539]\tLoss_D: 0.2728\tLoss_G: 0.5322\n",
      "[139/150][0/539]\tLoss_D: 0.0157\tLoss_G: 0.6844\n",
      "[139/150][50/539]\tLoss_D: 0.0616\tLoss_G: 0.4300\n",
      "[139/150][100/539]\tLoss_D: 0.0117\tLoss_G: 0.6678\n",
      "[139/150][150/539]\tLoss_D: 0.1125\tLoss_G: 0.5407\n",
      "[139/150][200/539]\tLoss_D: 0.0412\tLoss_G: 0.2788\n",
      "[139/150][250/539]\tLoss_D: 0.1562\tLoss_G: 0.5672\n",
      "[139/150][300/539]\tLoss_D: 0.1147\tLoss_G: 0.3298\n",
      "[139/150][350/539]\tLoss_D: 0.1559\tLoss_G: 0.3619\n",
      "[139/150][400/539]\tLoss_D: 0.0538\tLoss_G: 0.6027\n",
      "[139/150][450/539]\tLoss_D: 0.0957\tLoss_G: 0.5505\n",
      "[139/150][500/539]\tLoss_D: 0.2755\tLoss_G: 0.4079\n",
      "[140/150][0/539]\tLoss_D: 0.3424\tLoss_G: 0.9405\n",
      "[140/150][50/539]\tLoss_D: 0.2924\tLoss_G: 0.3990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140/150][100/539]\tLoss_D: 0.0533\tLoss_G: 0.2216\n",
      "[140/150][150/539]\tLoss_D: 0.0501\tLoss_G: 0.6026\n",
      "[140/150][200/539]\tLoss_D: 0.1773\tLoss_G: 0.5246\n",
      "[140/150][250/539]\tLoss_D: 0.1821\tLoss_G: 0.5697\n",
      "[140/150][300/539]\tLoss_D: 0.3020\tLoss_G: 0.3968\n",
      "[140/150][350/539]\tLoss_D: 0.0665\tLoss_G: 0.4936\n",
      "[140/150][400/539]\tLoss_D: 0.1324\tLoss_G: 0.2656\n",
      "[140/150][450/539]\tLoss_D: 0.5472\tLoss_G: 0.0844\n",
      "[140/150][500/539]\tLoss_D: 0.0800\tLoss_G: 0.4845\n",
      "[141/150][0/539]\tLoss_D: 0.0532\tLoss_G: 0.7722\n",
      "[141/150][50/539]\tLoss_D: 0.1885\tLoss_G: 0.0999\n",
      "[141/150][100/539]\tLoss_D: 0.2640\tLoss_G: 0.1943\n",
      "[141/150][150/539]\tLoss_D: 0.0521\tLoss_G: 0.5953\n",
      "[141/150][200/539]\tLoss_D: 0.3365\tLoss_G: 0.3261\n",
      "[141/150][250/539]\tLoss_D: 0.5894\tLoss_G: 0.2261\n",
      "[141/150][300/539]\tLoss_D: 0.0800\tLoss_G: 0.2990\n",
      "[141/150][350/539]\tLoss_D: 0.1549\tLoss_G: 0.6585\n",
      "[141/150][400/539]\tLoss_D: 0.1579\tLoss_G: 0.6501\n",
      "[141/150][450/539]\tLoss_D: 0.0351\tLoss_G: 0.5151\n",
      "[141/150][500/539]\tLoss_D: 0.2608\tLoss_G: 0.6191\n",
      "[142/150][0/539]\tLoss_D: 0.1432\tLoss_G: 0.3832\n",
      "[142/150][50/539]\tLoss_D: 0.1823\tLoss_G: 0.5463\n",
      "[142/150][100/539]\tLoss_D: 0.2991\tLoss_G: 0.5476\n",
      "[142/150][150/539]\tLoss_D: 0.3764\tLoss_G: 0.4727\n",
      "[142/150][200/539]\tLoss_D: 0.1938\tLoss_G: 0.4041\n",
      "[142/150][250/539]\tLoss_D: 0.0445\tLoss_G: 0.6299\n",
      "[142/150][300/539]\tLoss_D: 0.5656\tLoss_G: 0.4985\n",
      "[142/150][350/539]\tLoss_D: 0.3181\tLoss_G: 0.6732\n",
      "[142/150][400/539]\tLoss_D: 0.1213\tLoss_G: 0.4486\n",
      "[142/150][450/539]\tLoss_D: 0.1979\tLoss_G: 0.3906\n",
      "[142/150][500/539]\tLoss_D: 0.0589\tLoss_G: 0.5235\n",
      "[143/150][0/539]\tLoss_D: 0.1896\tLoss_G: 0.5969\n",
      "[143/150][50/539]\tLoss_D: 0.1173\tLoss_G: 0.6677\n",
      "[143/150][100/539]\tLoss_D: 0.2660\tLoss_G: 0.2812\n",
      "[143/150][150/539]\tLoss_D: 0.1946\tLoss_G: 0.2866\n",
      "[143/150][200/539]\tLoss_D: 0.0684\tLoss_G: 0.6422\n",
      "[143/150][250/539]\tLoss_D: 0.0479\tLoss_G: 0.6228\n",
      "[143/150][300/539]\tLoss_D: 0.1684\tLoss_G: 0.5369\n",
      "[143/150][350/539]\tLoss_D: 0.3083\tLoss_G: 0.2720\n",
      "[143/150][400/539]\tLoss_D: 0.3248\tLoss_G: 0.5253\n",
      "[143/150][450/539]\tLoss_D: 0.1479\tLoss_G: 0.7331\n",
      "[143/150][500/539]\tLoss_D: 0.0596\tLoss_G: 0.4354\n",
      "[144/150][0/539]\tLoss_D: 0.1924\tLoss_G: 0.7159\n",
      "[144/150][50/539]\tLoss_D: 0.1242\tLoss_G: 0.5607\n",
      "[144/150][100/539]\tLoss_D: 0.0613\tLoss_G: 0.4538\n",
      "[144/150][150/539]\tLoss_D: 0.3458\tLoss_G: 0.4821\n",
      "[144/150][200/539]\tLoss_D: 0.2467\tLoss_G: 0.4473\n",
      "[144/150][250/539]\tLoss_D: 0.0257\tLoss_G: 0.6216\n",
      "[144/150][300/539]\tLoss_D: 0.1757\tLoss_G: 0.3708\n",
      "[144/150][350/539]\tLoss_D: 0.0348\tLoss_G: 0.4940\n",
      "[144/150][400/539]\tLoss_D: 0.2873\tLoss_G: 0.7190\n",
      "[144/150][450/539]\tLoss_D: 0.1051\tLoss_G: 0.7053\n",
      "[144/150][500/539]\tLoss_D: 0.2589\tLoss_G: 0.2707\n",
      "[145/150][0/539]\tLoss_D: 0.2921\tLoss_G: 0.5308\n",
      "[145/150][50/539]\tLoss_D: 0.1881\tLoss_G: 0.4386\n",
      "[145/150][100/539]\tLoss_D: 0.1731\tLoss_G: 0.4231\n",
      "[145/150][150/539]\tLoss_D: 0.1058\tLoss_G: 0.2103\n",
      "[145/150][200/539]\tLoss_D: 0.1061\tLoss_G: 0.8996\n",
      "[145/150][250/539]\tLoss_D: 0.1400\tLoss_G: 0.5086\n",
      "[145/150][300/539]\tLoss_D: 0.3726\tLoss_G: 0.7775\n",
      "[145/150][350/539]\tLoss_D: 0.2578\tLoss_G: 0.4344\n",
      "[145/150][400/539]\tLoss_D: 0.0624\tLoss_G: 0.4791\n",
      "[145/150][450/539]\tLoss_D: 0.4886\tLoss_G: 0.1006\n",
      "[145/150][500/539]\tLoss_D: 0.1496\tLoss_G: 0.5101\n",
      "[146/150][0/539]\tLoss_D: 0.1626\tLoss_G: 0.5241\n",
      "[146/150][50/539]\tLoss_D: 0.0690\tLoss_G: 0.3929\n",
      "[146/150][100/539]\tLoss_D: 0.0499\tLoss_G: 0.7398\n",
      "[146/150][150/539]\tLoss_D: 0.0886\tLoss_G: 0.3164\n",
      "[146/150][200/539]\tLoss_D: 0.2048\tLoss_G: 0.2646\n",
      "[146/150][250/539]\tLoss_D: 0.0963\tLoss_G: 0.5537\n",
      "[146/150][300/539]\tLoss_D: 0.2019\tLoss_G: 0.4245\n",
      "[146/150][350/539]\tLoss_D: 0.1870\tLoss_G: 0.2220\n",
      "[146/150][400/539]\tLoss_D: 0.0564\tLoss_G: 0.8585\n",
      "[146/150][450/539]\tLoss_D: 0.3438\tLoss_G: 0.1361\n",
      "[146/150][500/539]\tLoss_D: 0.0891\tLoss_G: 0.3849\n",
      "[147/150][0/539]\tLoss_D: 0.2529\tLoss_G: 0.4210\n",
      "[147/150][50/539]\tLoss_D: 0.2536\tLoss_G: 0.2398\n",
      "[147/150][100/539]\tLoss_D: 0.0835\tLoss_G: 0.4141\n",
      "[147/150][150/539]\tLoss_D: 0.0719\tLoss_G: 0.4245\n",
      "[147/150][200/539]\tLoss_D: 0.1212\tLoss_G: 0.4625\n",
      "[147/150][250/539]\tLoss_D: 0.1773\tLoss_G: 0.4390\n",
      "[147/150][300/539]\tLoss_D: 0.1372\tLoss_G: 0.0605\n",
      "[147/150][350/539]\tLoss_D: 0.0238\tLoss_G: 0.7476\n",
      "[147/150][400/539]\tLoss_D: 0.1552\tLoss_G: 0.6793\n",
      "[147/150][450/539]\tLoss_D: 0.2223\tLoss_G: 0.3967\n",
      "[147/150][500/539]\tLoss_D: 0.2117\tLoss_G: 0.5124\n",
      "[148/150][0/539]\tLoss_D: 0.3099\tLoss_G: 0.3264\n",
      "[148/150][50/539]\tLoss_D: 0.0341\tLoss_G: 0.7407\n",
      "[148/150][100/539]\tLoss_D: 0.3230\tLoss_G: 0.3229\n",
      "[148/150][150/539]\tLoss_D: 0.0619\tLoss_G: 0.3926\n",
      "[148/150][200/539]\tLoss_D: 0.3322\tLoss_G: 0.6423\n",
      "[148/150][250/539]\tLoss_D: 0.0939\tLoss_G: 0.5568\n",
      "[148/150][300/539]\tLoss_D: 0.2336\tLoss_G: 0.6446\n",
      "[148/150][350/539]\tLoss_D: 0.2688\tLoss_G: 0.7194\n",
      "[148/150][400/539]\tLoss_D: 0.2139\tLoss_G: 0.5514\n",
      "[148/150][450/539]\tLoss_D: 0.1818\tLoss_G: 0.2505\n",
      "[148/150][500/539]\tLoss_D: 0.1292\tLoss_G: 0.7550\n",
      "[149/150][0/539]\tLoss_D: 0.0340\tLoss_G: 0.3693\n",
      "[149/150][50/539]\tLoss_D: 0.2730\tLoss_G: 0.3490\n",
      "[149/150][100/539]\tLoss_D: 0.2296\tLoss_G: 0.5367\n",
      "[149/150][150/539]\tLoss_D: 0.0752\tLoss_G: 0.5228\n",
      "[149/150][200/539]\tLoss_D: 0.2012\tLoss_G: 0.4260\n",
      "[149/150][250/539]\tLoss_D: 0.2931\tLoss_G: 0.3111\n",
      "[149/150][300/539]\tLoss_D: 0.1642\tLoss_G: 0.2495\n",
      "[149/150][350/539]\tLoss_D: 0.1095\tLoss_G: 0.6517\n",
      "[149/150][400/539]\tLoss_D: 0.1239\tLoss_G: 0.4498\n",
      "[149/150][450/539]\tLoss_D: 0.2603\tLoss_G: 0.2284\n",
      "[149/150][500/539]\tLoss_D: 0.2014\tLoss_G: 0.4706\n"
     ]
    }
   ],
   "source": [
    "Tensor = torch.cuda.FloatTensor\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = netG(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = criterion(netD(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        real_loss = criterion(netD(real_imgs), valid)\n",
    "        fake_loss = criterion(netD(gen_imgs.detach()), fake)\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     d_loss.item(), g_loss.item()))\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == 50-1) and (i == len(dataloader)-1)):\n",
    "            #with torch.no_grad():\n",
    "                #fake = netG(fixed_noise).detach().cpu()\n",
    "            #img_list.append(vutils.make_grid(fake, padding=0, normalize=True))\n",
    "            save_image(gen_imgs.data[:25], \"lsganimages/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "-------\n",
    "\n",
    "Finally, lets check out how we did. Here, we will look at three\n",
    "different results. First, we will see how D and G’s losses changed\n",
    "during training. Second, we will visualize G’s output on the fixed_noise\n",
    "batch for every epoch. And third, we will look at a batch of real data\n",
    "next to a batch of fake data from G.\n",
    "\n",
    "**Loss versus training iteration**\n",
    "\n",
    "Below is a plot of D & G’s losses versus training iterations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization of G’s progression**\n",
    "\n",
    "Remember how we saved the generator’s output on the fixed_noise batch\n",
    "after every epoch of training. Now, we can visualize the training\n",
    "progression of G with an animation. Press the play button to start the\n",
    "animation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-77092cc855f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(type(img_list[0]))\n",
    "print(img_list[0].shape)\n",
    "for i in range(len(img_list)):\n",
    "    img_list[i]=img_list[i].detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real Images vs. Fake Images**\n",
    "\n",
    "Finally, lets take a look at some real images and fake images side by\n",
    "side.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to Go Next\n",
    "----------------\n",
    "\n",
    "We have reached the end of our journey, but there are several places you\n",
    "could go from here. You could:\n",
    "\n",
    "-  Train for longer to see how good the results get\n",
    "-  Modify this model to take a different dataset and possibly change the\n",
    "   size of the images and the model architecture\n",
    "-  Check out some other cool GAN projects\n",
    "   `here <https://github.com/nashory/gans-awesome-applications>`__\n",
    "-  Create GANs that generate\n",
    "   `music <https://deepmind.com/blog/wavenet-generative-model-raw-audio/>`__\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img_list[0]))\n",
    "#print(img_list[0])\n",
    "print(img_list[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#f=open('FakeImage.txt','w')\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "for idx, item in enumerate(img_list):\n",
    "    save_image(item, 'FakeImageFolder2/img'+str(idx)+'.png')\n",
    "\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
